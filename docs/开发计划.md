# PodFlow 项目开发计划

> **版本**: v1.0  
> **创建日期**: 2025-12-23  
> **项目目标**: 打造本地优先的 AI 播客学习工具

---

## 目录
- [一、数据库设计方案](#一数据库设计方案)
- [二、开发策略](#二开发策略)
- [三、原子任务拆分](#三原子任务拆分)
- [四、开发节奏](#四开发节奏)
- [五、关键技术决策](#五关键技术决策)

---

## 一、数据库设计方案
表格版本：
https://docs.google.com/document/d/1NFLItC1df_0fSSBD1SvNeDVP0aP3Ap4Gj645jEeMcBU/edit?usp=sharing

### 核心关联关系

```
Podcast (播客) 
  ↓ 1:N
Episode (单集/音频文件)
  ↓ 1:N
AudioSegment (音频虚拟分段) ← 新增！用于异步识别
  ↓ 1:N
TranscriptCue (字幕片段，含 speaker) ← 对应 PRD 的 cue
  ↓ 1:N
Highlight (用户划线)
  ↓ 1:1
Note (笔记：underline/thought/ai_query)
  ↓ 0:1
AIQueryRecord (AI 查询记录)
```

### 文件存储策略

**采用虚拟分段 + 临时文件方案**（存储优化：仅保留一份完整音频）

```
backend/data/
├── audios/                          # 原始完整音频（唯一存储）
│   ├── abc123def456.mp3             # 使用 MD5 hash 命名
│   └── 789ghi012jkl.mp3
└── transcripts/                     # 字幕文件（可选，JSON 格式）
    ├── abc123def456.json            # 全量字幕
    └── abc123def456/
        ├── segment_001.json         # 分段字幕缓存
        └── segment_002.json

说明：
- 不物理切割音频文件（节省 50% 存储空间）
- 转录时用 FFmpeg 提取片段到临时文件（/tmp/）
- 转录完成后自动删除临时文件
```

---

### 数据表设计

#### 1. Podcast（播客）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| title | String | 播客名称（如 "Lenny's Podcast"） |
| source_url | String | 原始链接（用户提供），**唯一索引** ⭐ |
| description | Text | 播客描述 |
| cover_image | String | 封面图片路径 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- 本地音频可不关联 Podcast（`podcast_id` 可为空）
- **`source_url` 唯一性约束**：防止重复添加同一个播客源
- **允许同名 Podcast**：不同源的播客可以有相同的 title（如 "The Daily"）
- **去重逻辑**：添加 Podcast 前，先检查 source_url 是否已存在
- **NULL 值不受限制**：多个 Podcast 可以有 source_url=NULL（手动创建的播客）

**索引优化**：
```sql
CREATE UNIQUE INDEX idx_source_url ON podcasts(source_url);
CREATE INDEX idx_title ON podcasts(title);
```

---

#### 2. Episode（单集/音频文件）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| podcast_id | Integer | 外键 → Podcast（可为空，本地音频无 podcast） |
| **文件信息** | | |
| title | String | 单集标题 |
| original_filename | String | 用户上传的原始文件名 |
| original_path | String | 用户选择的原始路径（仅供参考） |
| audio_path | String | 项目内存储路径（实际使用） |
| file_hash | String | MD5 hash（唯一索引，用于去重） |
| file_size | Integer | 文件大小（字节） |
| duration | Float | 音频总时长（秒） |
| **分段信息** | | |
| needs_segmentation | Boolean | 是否需要分段（duration > 180s） |
| segment_duration | Integer | 每段时长（默认 180 秒） |
| total_segments | Integer | 总段数 |
| **转录状态**（双层设计：用户层 + 调试层） | | |
| transcription_started_at | DateTime | 开始转录时间（Episode 级别时间戳） |
| transcription_completed_at | DateTime | 完成转录时间（所有段完成时设置） |
| **元数据** | | |
| language | String | 语言代码（默认 "en-US"） |
| created_at | DateTime | 创建时间 |
| updated_at | DateTime | 更新时间 |

**设计要点**：
- `file_hash` 用于去重：相同文件只存储一次
- `needs_segmentation`：duration > 180s 时为 True
- `audio_path`：保存到项目目录，不依赖用户原始路径
- **存储策略**：只保留完整音频，不切割物理文件
- **节目名称优化**（方案 1 - 消除数据冗余）：
  - ❌ 删除 `show_name` 字段（避免与 Podcast.title 重复）
  - ✅ 使用 `@property` 动态获取：
    - 如果关联了 Podcast → 返回 `Podcast.title`
    - 如果是本地音频 → 返回 `"本地音频"`
  - ✅ 符合数据库第三范式（3NF），保证数据一致性
  - ✅ 使用 SQLAlchemy `joinedload` 优化查询性能

- **转录状态优化**（双层设计 - 关注点分离）：
  - ❌ 删除数据库字段：`transcription_status`、`transcription_progress`、`error_message`
  - ✅ **用户界面层**（隐藏技术细节）：
    - `transcription_progress`: 返回百分比（0-100），用于进度条
    - `transcription_status_display`: 返回友好文本（"正在转录中..."/"转录完成"）
    - `estimated_time_remaining`: 返回预计剩余秒数（用户关心"还要等多久"）
    - **不暴露分段信息**：用户不需要知道"被切成几段"
  - ✅ **开发调试层**（完整技术数据）：
    - `transcription_stats`: 返回段数统计（total/completed/failed/processing/pending）
    - `failed_segments_detail`: 返回失败段的详细错误信息
    - **仅供日志、监控、调试使用**
  - ✅ 设计原则：
    - 用户只看到结果（进度、剩余时间），不看到过程（分段）
    - 开发者看到完整数据（段数、错误详情），便于排查问题
    - 数据源单一（Segment 状态为准），保证一致性

**索引优化**：
```sql
CREATE UNIQUE INDEX idx_file_hash ON episodes(file_hash);
-- ❌ 删除：CREATE INDEX idx_transcription_status（该字段已不存在）
```

---

#### 3. AudioSegment（音频虚拟分段）- 新增！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| **分段信息** | | |
| segment_index | Integer | 段序号（从 0 开始） |
| segment_id | String | 分段 ID（如 "segment_001"） |
| segment_path | String | 物理文件路径（虚拟分段为 NULL） |
| **时间范围**（核心） | | |
| start_time | Float | 在原音频中的开始时间（秒） |
| end_time | Float | 在原音频中的结束时间（秒） |
| duration | Float | 分段时长（秒） |
| **识别状态** | | |
| status | String | pending/processing/completed/failed |
| error_message | Text | 错误信息 |
| recognized_at | DateTime | 识别完成时间 |
| **字幕关联** | | |
| cue_count | Integer | 该段包含的字幕数量 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- **虚拟分段**：`segment_path` 为 NULL，不存储物理文件
- 只记录时间范围（`start_time`, `end_time`）
- 转录时用 FFmpeg 实时提取到临时文件
- 支持异步识别：用户滚动时按需识别后续 segment

**索引优化**：
```sql
CREATE INDEX idx_episode_segment ON audio_segments(episode_id, segment_index);
CREATE INDEX idx_segment_status ON audio_segments(status);
```

---

#### 4. TranscriptCue（字幕片段）- 重命名！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| segment_id | Integer | 外键 → AudioSegment（可选） |
| **字幕内容**（对应 PRD 的 cue 结构） | | |
| cue_index | Integer | Episode 级别的全局索引（1, 2, 3...） ← 重命名！ |
| start_time | Float | 开始时间戳（秒） |
| end_time | Float | 结束时间戳（秒） |
| speaker | String | 说话人（如 "Lenny", "SPEAKER_01", "Unknown"） |
| text | Text | 字幕文本 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- 对应 PRD 中的 `cue` 概念（不是 segment）
- `speaker` 字段：支持说话人标识（PRD 必需），默认 "Unknown"
- **`cue_index`**：Episode 级别的全局索引（Critical）
  - 从 1 开始递增（1, 2, 3, 4...）
  - 即使异步分段识别，也要保证全局连续性
  - 用于排序显示和跨 cue 划线的范围判断
- `start_time`/`end_time`：相对于原始音频的绝对时间

**PRD 字幕格式对应**：
```json
{
  "cues": [
    {
      "id": 0,                      → cue_index（从 1 开始更直观）
      "start": 0.28,                → start_time
      "end": 2.22,                  → end_time
      "speaker": "Lenny",           → speaker
      "text": "Thank you..."        → text
    }
  ]
}
```

**索引优化**：
```sql
-- Episode 级别的全局索引（用于排序和范围查询）
CREATE INDEX idx_episode_cue_index ON transcript_cues(episode_id, cue_index);
-- Segment 关联索引（用于异步识别）
CREATE INDEX idx_segment_cue ON transcript_cues(segment_id, cue_index);
-- 时间范围索引（用于音频同步）
CREATE INDEX idx_episode_time ON transcript_cues(episode_id, start_time);
```

---

#### 5. Highlight（用户划线）- 支持跨 Cue 划线！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| **划线范围**（支持跨 Cue） ← Critical！ | | |
| start_cue_id | Integer | 外键 → TranscriptCue（起始 cue） |
| end_cue_id | Integer | 外键 → TranscriptCue（结束 cue） |
| start_offset | Integer | 在起始 cue 内的字符位置 |
| end_offset | Integer | 在结束 cue 内的字符位置 |
| **划线内容**（快照） | | |
| highlighted_text | Text | 被划线的文本内容（冗余字段，方便前端快速渲染） |
| **样式** | | |
| color | String | 划线颜色（默认 #9C27B0，紫色） |
| created_at | DateTime | 创建时间 |

**设计要点**（Critical - 支持跨句子/跨段落划线）：
- **支持跨 Cue 划线**（PRD 5.3.b.ii："划线内容可以是单词、句子或者段落"）
  - 单句划线：`start_cue_id == end_cue_id`
  - 跨句划线：`start_cue_id < end_cue_id`
- **前端渲染逻辑**：
  ```javascript
  // 1. 找到起始 cue，从 start_offset 高亮到末尾
  // 2. 找到结束 cue，从 0 高亮到 end_offset
  // 3. 中间的 cue（cue_index 在两者之间）全量高亮
  for (let i = start_cue.cue_index; i <= end_cue.cue_index; i++) {
    if (i === start_cue.cue_index) {
      highlightText(cue.text, start_offset, cue.text.length);
    } else if (i === end_cue.cue_index) {
      highlightText(cue.text, 0, end_offset);
    } else {
      highlightText(cue.text, 0, cue.text.length); // 完整高亮
    }
  }
  ```
- **颜色默认紫色**（PRD 318行："被划线的字幕出现紫色下划线"）
- `highlighted_text` 是冗余字段（快照），避免每次都拼凑多个 cue 的文本

**索引优化**：
```sql
-- Episode 级别的划线查询
CREATE INDEX idx_episode_highlight ON highlights(episode_id);
-- 范围查询优化（查找某个 cue 上的所有划线）
CREATE INDEX idx_highlight_start_cue ON highlights(start_cue_id);
CREATE INDEX idx_highlight_end_cue ON highlights(end_cue_id);
-- 复合索引（提高查询性能）
CREATE INDEX idx_highlight_episode_range ON highlights(episode_id, start_cue_id, end_cue_id);
```

---

#### 6. Note（笔记）- 明确 AI 查询转化关系！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| highlight_id | Integer | 外键 → Highlight（必需） |
| **来源追踪** ← 新增！ | | |
| origin_ai_query_id | Integer | 外键 → AIQueryRecord（可选，标记来源） |
| **笔记内容** | | |
| content | Text | 笔记内容（underline 类型时为空） |
| note_type | String | underline/thought/ai_card ← 修正！ |
| **元数据** | | |
| created_at | DateTime | 创建时间 |
| updated_at | DateTime | 更新时间 |

**设计要点**（Critical - AI 查询与笔记的转化关系）：
- **`note_type` 三种类型**：
  - `underline`：纯划线（只有下划线样式，不显示笔记卡片，content 为空）
  - `thought`：用户想法（显示笔记卡片，用户手动输入）
  - **`ai_card`**：保存的 AI 查询结果（显示笔记卡片，来自 AI）← 修正命名！
  
- **AI 查询到笔记的转化逻辑**（PRD 6.2.4.e）：
  1. 用户划线 → 点击"AI 查询" → 创建 `AIQueryRecord`（临时）
  2. AI 返回结果 → 前端展示"AI查询卡片"（临时 UI）
  3. 用户点击卡片上的"笔记图标" → 创建 `Note`（持久化）：
     - `note_type = 'ai_card'`
     - `content = AIQueryRecord.response`
     - `origin_ai_query_id = AIQueryRecord.id`（记录来源）
  4. 右侧笔记栏渲染所有 `Note` 表数据（不包括未保存的 AI 查询）

- **`origin_ai_query_id` 的作用**：
  - 追溯笔记来源：这条笔记是从哪次 AI 查询保存的
  - 避免重复查询：用户再次划同样的内容，可以直接从 `AIQueryRecord` 缓存加载
  - 数据分析：统计用户最常查询的词汇/短语

- **`highlight_id` 必需**：所有笔记都源于划线操作

- **笔记位置动态计算**：通过 `Note → Highlight → TranscriptCue` 关联链，在前端根据 Cue 的 DOM 位置（`offsetTop`）动态渲染笔记卡片（PRD 390行："笔记卡片的顶部在用户的'划线源'顶部上面24px的位置"）

**索引优化**：
```sql
-- 基础索引
CREATE INDEX idx_episode_note ON notes(episode_id);
CREATE INDEX idx_highlight_note ON notes(highlight_id);
CREATE INDEX idx_note_type ON notes(note_type);
CREATE INDEX idx_origin_ai_query ON notes(origin_ai_query_id);
-- 复合索引（提高查询性能）
CREATE INDEX idx_note_episode_type ON notes(episode_id, note_type);
CREATE INDEX idx_note_episode_highlight ON notes(episode_id, highlight_id);
```

---

#### 7. AIQueryRecord（AI 查询记录）- 作为缓存/日志！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| highlight_id | Integer | 外键 → Highlight（必需） |
| **查询内容** | | |
| query_text | Text | 用户查询的文本（划线内容） |
| context_text | Text | 上下文（相邻 2-3 个 cue 的文本） ← 重命名！ |
| response_text | Text | AI 返回的结果 ← 重命名！ |
| **查询类型和提供商** | | |
| query_type | String | word_translation/phrase_explanation/concept |
| provider | String | AI 提供商（如 "gpt-3.5", "google"） ← 新增！ |
| **状态** | | |
| status | String | processing/completed/failed |
| created_at | DateTime | 创建时间 |

**设计要点**（Critical - AI 查询作为缓存/日志）：
- **AIQueryRecord 的定位**：
  - **缓存**：避免重复查询同样的内容（节省 Token 成本）
  - **日志**：记录所有 AI 查询历史，用于数据分析
  - **临时存储**：用户可能查询了但没有保存为笔记

- **独立存在，不强依赖 Note**：
  - 用户划线 → 点"AI 查询" → 立即创建 `AIQueryRecord`
  - 用户可能不保存为笔记（只是临时查看）
  - 如果保存为笔记，Note 通过 `origin_ai_query_id` 反向关联

- **查询缓存逻辑**：
  ```python
  # 用户划线查询前，先检查是否已有缓存
  existing = db.query(AIQueryRecord).filter(
      AIQueryRecord.highlight_id == highlight.id,
      AIQueryRecord.query_type == "word_translation"
  ).first()
  
  if existing and existing.status == "completed":
      return existing.response_text  # 直接返回缓存
  else:
      # 调用 AI API
      response = ai_service.query(...)
      # 保存新记录
  ```

- **`context_text` 的构建**：包含相邻 2-3 个 TranscriptCue 的文本，用于专有名词识别
- **`provider` 字段**：标记 AI 提供商，便于后续分析不同模型的效果

**反向关联**：
- `AIQueryRecord` → 可能被多个 `Note` 引用（`origin_ai_query_id`）
- 但删除 `AIQueryRecord` 不会删除 `Note`（Note 已经保存了 content）

---

#### 8. Vocabulary（生词本）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| word | String | 单词（索引） |
| definition | Text | 释义 |
| episode_id | Integer | 外键 → Episode |
| highlight_id | Integer | 外键 → Highlight（可选） |
| created_at | DateTime | 创建时间 |

---

### 级联删除规则（Critical）

**为什么需要级联删除**：
- PRD 326行："删除包括：笔记卡片、下划线效果、本地json数据"
- 保证数据一致性：删除父记录时自动清理所有关联的子记录
- 避免孤儿数据：防止数据库中出现无效的外键引用

**SQLAlchemy 实现**：

```python
# Episode 被删除 → 级联删除所有关联数据
class Episode(Base):
    segments = relationship("AudioSegment", back_populates="episode", cascade="all, delete-orphan")
    cues = relationship("TranscriptCue", back_populates="episode", cascade="all, delete-orphan")
    highlights = relationship("Highlight", back_populates="episode", cascade="all, delete-orphan")
    notes = relationship("Note", back_populates="episode", cascade="all, delete-orphan")
    vocabulary = relationship("Vocabulary", back_populates="episode", cascade="all, delete-orphan")

# Highlight 被删除 → 级联删除关联的 Note 和 AIQueryRecord
class Highlight(Base):
    # 支持跨 Cue 划线（新增）
    start_cue = relationship("TranscriptCue", foreign_keys="Highlight.start_cue_id")
    end_cue = relationship("TranscriptCue", foreign_keys="Highlight.end_cue_id")
    
    # 级联删除
    notes = relationship("Note", back_populates="highlight", cascade="all, delete-orphan")
    ai_queries = relationship("AIQueryRecord", back_populates="highlight", cascade="all, delete-orphan")

# Note 不再级联删除 AIQueryRecord（反向关联）
class Note(Base):
    # Note 可能来自 AI 查询，但不拥有它
    origin_ai_query = relationship("AIQueryRecord", foreign_keys="Note.origin_ai_query_id")  # 不级联删除

# AIQueryRecord 独立存在，不依赖 Note
class AIQueryRecord(Base):
    highlight = relationship("Highlight", back_populates="ai_queries")
    # 反向：可能被多个 Note 引用，但不拥有它们

# Podcast 被删除 → Episode 不删除（设置为 NULL）
class Podcast(Base):
    episodes = relationship("Episode", back_populates="podcast")  # 不级联删除

class Episode(Base):
    podcast_id = Column(Integer, ForeignKey("podcasts.id", ondelete="SET NULL"), nullable=True)
```

**级联删除链**（更新）：

```
删除 Episode 
  → 自动删除 AudioSegment
  → 自动删除 TranscriptCue
  → 自动删除 Highlight
    → 自动删除 Note（Note.origin_ai_query_id 仍保留，但不影响）
    → 自动删除 AIQueryRecord
  → 自动删除 Vocabulary

删除 Highlight
  → 自动删除 Note
  → 自动删除 AIQueryRecord

删除 Note
  → **不删除** AIQueryRecord（反向关联，Note 不拥有 AIQueryRecord）

删除 AIQueryRecord
  → **不删除** Note（Note 已经保存了 content，origin_ai_query_id 只是标记来源）

删除 Podcast
  → Episode 的 podcast_id 设置为 NULL（保留本地音频）
```

**关键变化**：
- `Note` 和 `AIQueryRecord` 的关系改为**反向关联**（Note 引用 AIQueryRecord，但不拥有它）
- 删除 `AIQueryRecord` 不会影响 `Note`（笔记已持久化）
- 删除 `Note` 不会影响 `AIQueryRecord`（查询记录作为缓存/日志保留）

**测试用例**（Task 1.1 必须包含）：

```python
def test_cascade_delete_episode(db):
    """测试删除 Episode 时级联删除所有关联数据"""
    episode = create_test_episode()
    segment = create_test_segment(episode.id)
    cue = create_test_cue(episode.id, segment.id)
    highlight = create_test_highlight(episode.id, cue.id, cue.id)  # 单句划线
    note = create_test_note(episode.id, highlight.id)
    ai_query = create_test_ai_query(highlight.id)
    
    # 删除 Episode
    db.delete(episode)
    db.commit()
    
    # 验证所有关联数据被删除
    assert db.query(AudioSegment).filter_by(episode_id=episode.id).count() == 0
    assert db.query(TranscriptCue).filter_by(episode_id=episode.id).count() == 0
    assert db.query(Highlight).filter_by(episode_id=episode.id).count() == 0
    assert db.query(Note).filter_by(episode_id=episode.id).count() == 0
    assert db.query(AIQueryRecord).filter_by(highlight_id=highlight.id).count() == 0


def test_cross_cue_highlight(db):
    """测试跨 Cue 划线（Critical）"""
    episode = create_test_episode()
    cue1 = create_test_cue(episode.id, cue_index=1, text="Hello world.")
    cue2 = create_test_cue(episode.id, cue_index=2, text="This is a test.")
    cue3 = create_test_cue(episode.id, cue_index=3, text="Thank you.")
    
    # 创建跨 Cue 划线（从 cue1 的 "world" 到 cue3 的 "Thank"）
    highlight = Highlight(
        episode_id=episode.id,
        start_cue_id=cue1.id,
        end_cue_id=cue3.id,
        start_offset=6,  # "world" 的起始位置
        end_offset=5,    # "Thank" 的结束位置
        highlighted_text="world. This is a test. Thank",
        color="#9C27B0"
    )
    db.add(highlight)
    db.commit()
    
    # 验证关联
    assert highlight.start_cue_id == cue1.id
    assert highlight.end_cue_id == cue3.id
    
    # 验证前端渲染逻辑（伪代码）
    # cue1: 高亮 "world."（从 offset 6 到末尾）
    # cue2: 完整高亮 "This is a test."
    # cue3: 高亮 "Thank"（从 0 到 offset 5）


def test_ai_query_to_note_conversion(db):
    """测试 AI 查询转笔记的逻辑（Critical）"""
    episode = create_test_episode()
    cue = create_test_cue(episode.id, cue_index=1)
    highlight = create_test_highlight(episode.id, cue.id, cue.id)
    
    # 1. 用户划线 → AI 查询
    ai_query = AIQueryRecord(
        highlight_id=highlight.id,
        query_text="taxonomy",
        context_text="...",
        response_text="n. 分类学；分类法",
        query_type="word_translation",
        provider="gpt-3.5",
        status="completed"
    )
    db.add(ai_query)
    db.commit()
    
    # 2. 用户点击"保存笔记" → 创建 Note
    note = Note(
        episode_id=episode.id,
        highlight_id=highlight.id,
        origin_ai_query_id=ai_query.id,  # 标记来源
        content=ai_query.response_text,
        note_type="ai_card"
    )
    db.add(note)
    db.commit()
    
    # 验证关联
    assert note.origin_ai_query_id == ai_query.id
    assert note.note_type == "ai_card"
    
    # 3. 删除 AIQueryRecord → Note 保留
    db.delete(ai_query)
    db.commit()
    
    assert db.query(Note).filter_by(id=note.id).count() == 1  # Note 仍存在
    assert note.origin_ai_query_id == ai_query.id  # 外键保留（但记录已不存在）


def test_episode_show_name_property(db):
    """测试 Episode 的 show_name 属性（方案 1 优化）"""
    # 1. 创建关联 Podcast 的 Episode
    podcast = Podcast(title="Lenny's Podcast")
    db.add(podcast)
    db.commit()
    
    episode_with_podcast = Episode(
        title="Episode 1",
        podcast_id=podcast.id,
        file_hash="hash001"
    )
    db.add(episode_with_podcast)
    db.commit()
    
    # 验证 show_name 从 Podcast 获取
    assert episode_with_podcast.show_name == "Lenny's Podcast"
    assert episode_with_podcast.show_name == podcast.title
    
    # 2. 创建本地音频（无 Podcast）
    local_episode = Episode(
        title="Local Audio",
        podcast_id=None,
        file_hash="hash002"
    )
    db.add(local_episode)
    db.commit()
    
    # 验证 show_name 返回默认值
    assert local_episode.show_name == "本地音频"
    
    # 3. 使用 joinedload 优化查询（避免 N+1 问题）
    from sqlalchemy.orm import joinedload
    
    episodes = db.query(Episode).options(joinedload(Episode.podcast)).all()
    
    # 访问 show_name 不会触发额外查询
    for ep in episodes:
        _ = ep.show_name  # 高效访问
    
    assert len(episodes) == 2
```

---

### 存储优化策略总结

| 方案 | 存储占用 | 实现复杂度 | 采用 |
|------|---------|-----------|-----|
| 物理分段（切割文件） | 200% | 简单 | ❌ |
| **虚拟分段（临时文件）** | **100%** | **简单** | **✅** |
| 符号链接 | 100% | 复杂 | ❌ |

**虚拟分段工作流程**：
1. 用户上传音频 → 保存到 `backend/data/audios/{file_hash}.mp3`
2. 创建虚拟分段 → `AudioSegment` 表记录时间范围，`segment_path = NULL`
3. 转录时 → 用 FFmpeg 提取片段到临时文件（`/tmp/temp_segment_123.mp3`）
4. 调用 Whisper 转录临时文件
5. 转录完成 → 自动删除临时文件

**关键代码**（修正 FFmpeg 参数 ⚠️）：
```python
with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp:  # 改为 WAV
    # 用 FFmpeg 提取片段并转码为 Whisper 原生格式
    subprocess.run([
        "ffmpeg", "-y",
        "-i", episode.audio_path,
        "-ss", str(segment.start_time),
        "-t", str(segment.duration),
        # ⚠️ 不使用 -c copy！MP3 只能在关键帧切割，会导致时间戳偏移
        "-ar", "16000",      # Whisper 需要 16kHz 采样率
        "-ac", "1",          # 单声道
        "-c:a", "pcm_s16le", # PCM 编码，精准切割（秒级精度）
        temp.name
    ], check=True)
    # 转录临时文件（Whisper 无需再转码，加载更快）
    cues = whisper_service.transcribe(temp.name)
# with 语句结束后，临时文件自动删除
```

**关键修正说明**：
- ❌ **禁止使用 `-c copy`**：MP3 压缩格式只能在关键帧处切割，时间戳不精确
- ✅ **转码为 WAV（PCM）**：秒级精准切割，且 Whisper 内部也需要转为 16kHz Mono
- ✅ **性能影响可控**：3 分钟片段转码 < 2 秒（完全可接受）

---

## 二、开发策略

### 核心原则：后端优先 + TDD + 前后端并行迭代

#### 为什么后端优先？
1. **数据和逻辑核心**：Whisper 转录、数据库 CRUD、AI 查询都在后端
2. **前端依赖后端 API**：前端组件需要真实数据才能验证交互逻辑
3. **TDD 更容易实施**：后端测试比前端 UI 测试更易编写和验证

#### 开发阶段划分
- **阶段一（后端为主）**：搭建后端核心功能 API + 单元测试
- **阶段二（前后端并行）**：前端消费 API，后端根据前端反馈调整接口
- **阶段三（前端为主）**：UI 交互优化、状态管理、响应式布局

---

## 三、原子任务拆分

### 阶段 1：后端数据层 + Whisper 转录（Week 1）

#### Task 1.1：数据库模型重构
**优先级**: P0（最高）  
**预计工时**: 6 小时（增加了表数量和复杂度）

- [ ] **测试先行**：编写 `backend/tests/test_models_new.py`
  - 测试所有 8 个表创建成功
  - 测试外键关联：
    - Episode → Podcast（可选，ondelete="SET NULL"）
    - AudioSegment → Episode（cascade）
    - TranscriptCue → Episode & AudioSegment（cascade）
    - **Highlight → Episode & TranscriptCue（双外键：start_cue_id, end_cue_id）**
    - Note → Episode & Highlight & AIQueryRecord（origin_ai_query_id）
    - AIQueryRecord → Highlight（cascade）
    - Vocabulary → Episode & Highlight（cascade）
  
  - 测试数据插入和查询
  
  - **测试级联删除**（Critical，对应 PRD 326行）：
    - 删除 Episode → 验证 AudioSegment、TranscriptCue、Highlight、Note、AIQueryRecord、Vocabulary 全部被删除
    - 删除 Highlight → 验证 Note 和 AIQueryRecord 被删除
    - **删除 Note → AIQueryRecord 保留**（反向关联）
    - **删除 AIQueryRecord → Note 保留**（Note 已持久化）
    - 删除 Podcast → 验证 Episode 保留（podcast_id 设为 NULL）
  
  - **测试跨 Cue 划线**（Critical，对应用户建议）：
    - 单句划线：`start_cue_id == end_cue_id`
    - 跨句划线：`start_cue_id < end_cue_id`
    - 验证前端渲染逻辑的正确性（通过辅助函数）
  
  - **测试 AI 查询到笔记的转化**（Critical）：
    - 创建 AIQueryRecord → 保存为 Note → 验证 `origin_ai_query_id` 关联
    - 删除 AIQueryRecord → 验证 Note 保留
    - 验证 `note_type = 'ai_card'`
  
  - 测试唯一索引：`Episode.file_hash` 唯一性
  - 测试虚拟分段：创建 AudioSegment 时 `segment_path = NULL`
  
  - **测试新字段**：
    - TranscriptCue.cue_index 字段正常工作（Episode 级别全局索引）
    - Highlight 包含 start_cue_id 和 end_cue_id 字段
    - Highlight.color 默认值为 "#9C27B0"（紫色）
    - Note 包含 origin_ai_query_id 字段
    - Note.note_type 支持 'underline', 'thought', 'ai_card'
    - Note 表不包含 position_top 和 user_avatar 字段
    - AIQueryRecord 包含 provider 字段
    - **Episode 表不包含 show_name 字段**（使用 @property 动态获取）
    - Episode.show_name 属性能正确返回 Podcast.title 或 "本地音频"
    - **Episode 表不包含 transcription_status/progress/error_message 字段**（双层设计）
    - **Episode 用户层属性**：
      - transcription_progress 返回百分比（0-100）
      - transcription_status_display 返回友好文本
      - estimated_time_remaining 返回预计剩余秒数
    - **Episode 调试层属性**：
      - transcription_stats 返回完整段数统计
      - failed_segments_detail 返回失败段详情

- [ ] **实现模型**：重构 `backend/app/models.py`
  - 添加 8 个新表模型：
    1. `Podcast`（播客）
    2. `Episode`（单集，含 file_hash、needs_segmentation 等）
       - **不包含 show_name 字段**（方案 1 优化）
       - **实现 @property show_name**：动态获取节目名称
       - **删除转录状态字段**（双层设计优化）
       - **实现转录状态 @property**（用户层 + 调试层）：
         
         ```python
         # ========== 用户界面层（简洁） ==========
         @property
         def transcription_progress(self):
             """返回百分比 0-100（用于进度条）"""
             if not self.segments:
                 return 0.0
             completed = sum(1 for s in self.segments if s.status == "completed")
             return round((completed / len(self.segments)) * 100, 2)
         
         @property
         def transcription_status_display(self):
             """返回友好的状态文本（隐藏技术细节）"""
             status_map = {
                 "pending": "等待转录",
                 "processing": "正在转录中...",
                 "completed": "转录完成",
                 "partial_failed": "部分转录失败，可继续使用",
                 "failed": "转录失败，请重试"
             }
             return status_map.get(self.transcription_status, "未知状态")
         
         @property
         def estimated_time_remaining(self):
             """返回预计剩余秒数（用户关心的信息）"""
             pending = sum(1 for s in self.segments if s.status in ["pending", "processing"])
             return int(pending * 180 * 0.4)  # 每段180s，转录速度0.4x
         
         # ========== 开发调试层（详细） ==========
         @property
         def transcription_stats(self):
             """返回完整的段数统计（仅供调试）"""
             if not self.segments:
                 return {"total_segments": 0, "completed_segments": 0, ...}
             return {
                 "total_segments": len(self.segments),
                 "completed_segments": sum(1 for s in self.segments if s.status == "completed"),
                 "failed_segments": sum(1 for s in self.segments if s.status == "failed"),
                 ...
             }
         
         @property
         def failed_segments_detail(self):
             """返回失败段的详细信息（仅供调试）"""
             return [
                 {"segment_id": s.segment_id, "error_message": s.error_message, ...}
                 for s in self.segments if s.status == "failed"
             ]
         ```
    3. `AudioSegment`（虚拟分段，segment_path 可为空）
    4. **`TranscriptCue`**（字幕片段，含 speaker、cue_index）
    5. **`Highlight`**（用户划线，支持跨 Cue：start_cue_id, end_cue_id）
    6. **`Note`**（笔记：underline/thought/ai_card，含 origin_ai_query_id）
    7. **`AIQueryRecord`**（AI 查询记录，含 provider，独立于 Note）
    8. `Vocabulary`（生词本）
  
  - 添加 SQLAlchemy `relationship` 关系映射：
    - **Highlight 的双外键关系**：`start_cue`, `end_cue`（支持跨 Cue 划线）
    - **Note 的反向关联**：`origin_ai_query`（不拥有 AIQueryRecord）
    - **AIQueryRecord 独立存在**：不被 Note 拥有
  
  - **配置级联删除规则**（Critical）：
    - Episode: `cascade="all, delete-orphan"`
    - Highlight: `cascade="all, delete-orphan"`
    - AIQueryRecord: 由 Highlight 级联删除
    - **Note 不级联删除 AIQueryRecord**（反向关联）
    - Podcast → Episode: `ondelete="SET NULL"`
  
  - 配置外键约束和索引（见数据库设计部分）
  
  - 添加默认值：
    - `TranscriptCue.speaker = "Unknown"`
    - `Highlight.color = "#9C27B0"`（紫色）
    - `AudioSegment.segment_path = None`（虚拟分段）
    - `AIQueryRecord.status = "processing"`

- [ ] **数据库迁移**
  - 删除旧的 `data/podflow.db`（如果存在）
  - 运行 `init_db()` 创建新表
  - 验证表结构（使用 SQLite 客户端查看）
  - 验证索引创建成功

- [ ] **验收标准**
  - [ ] 所有测试用例通过（绿色）
  - [ ] 数据库文件成功创建，包含 8 个表
  - [ ] 可以手动插入测试数据
  - [ ] `Episode.file_hash` 唯一索引生效
  - [ ] 虚拟分段测试通过（segment_path 为 NULL）
  - [ ] **级联删除测试全部通过**（删除父记录时子记录被自动清理）
  - [ ] **跨 Cue 划线测试通过**（Critical）：
    - 单句划线和跨句划线都能正确创建
    - 前端渲染逻辑验证通过
  - [ ] **AI 查询转笔记测试通过**（Critical）：
    - AIQueryRecord 可以转换为 Note
    - 删除 AIQueryRecord 不影响 Note
    - 删除 Note 不影响 AIQueryRecord
  - [ ] 新字段验证通过：
    - TranscriptCue 包含 cue_index 字段（Episode 级别全局索引）
    - Highlight 包含 start_cue_id 和 end_cue_id 字段
    - Highlight 默认颜色为紫色（#9C27B0）
    - Note 包含 origin_ai_query_id 字段
    - Note.note_type 支持 'underline', 'thought', 'ai_card'
    - Note 表不包含 position_top 和 user_avatar 字段
    - AIQueryRecord 包含 provider 字段
  - [ ] **Episode 表优化验证通过**（双层设计）：
    - Episode 表不包含 show_name 字段
    - Episode.show_name @property 能正确返回 Podcast.title
    - 本地音频（podcast_id=None）的 show_name 返回 "本地音频"
    - Episode 表不包含 transcription_status/progress/error_message 字段
    - **用户层属性验证**：
      - transcription_progress 返回正确的百分比
      - transcription_status_display 返回友好文本（无技术术语）
      - estimated_time_remaining 计算准确（基于剩余段数）
    - **调试层属性验证**：
      - transcription_stats 返回完整的段数统计
      - failed_segments_detail 返回失败段的详细信息
    - **关注点分离验证**：
      - 用户界面不显示段数信息（隐藏技术细节）
      - 调试界面显示完整数据（便于问题排查）
    - 使用 joinedload 查询时无 N+1 问题
  - [ ] 所有复合索引创建成功

---

#### Task 1.2：Whisper 转录服务实现（虚拟分段 + 临时文件）
**优先级**: P0  
**预计工时**: 10 小时（新增虚拟分段逻辑）

- [ ] **测试先行**：编写 `backend/tests/test_whisper_service.py`
  - 测试音频文件转录（提供测试音频文件 `test.mp3`）
  - 测试时间戳提取（验证 `start_time` 和 `end_time`）
  - 测试 speaker 识别（验证 `speaker` 字段）
  - 测试虚拟分段转录：
    - 用 FFmpeg 提取片段到临时文件
    - 转录完成后临时文件被删除
  - 测试异常处理：
    - 非 MP3 文件 → 返回错误
    - 超大文件（> 1GB） → 返回错误
    - 空文件 → 返回错误
    - FFmpeg 提取失败 → 返回错误

- [ ] **实现 Whisper 服务**：优化 `backend/app/services/whisper_service.py`
  - 实现 `transcribe(audio_path: str) -> List[Dict]`
    - 返回 cue 列表（包含 id, start, end, speaker, text）
    - 使用 Whisper `word_timestamps=True` 获取精准时间戳
    - 识别说话人（WhisperX diarization）
  - 实现 `extract_segment_to_temp(audio_path, start_time, duration) -> str`
    - 用 FFmpeg 提取片段到临时文件（WAV 格式）
    - 使用 `tempfile.NamedTemporaryFile(suffix=".wav")`
    - **修正 FFmpeg 参数**（Critical ⚠️）：
      ```python
      subprocess.run([
          "ffmpeg", "-y",
          "-i", audio_path,
          "-ss", str(start_time),
          "-t", str(duration),
          # ⚠️ 不使用 -c copy！改用精准转码
          "-ar", "16000",      # Whisper 需要 16kHz
          "-ac", "1",          # 单声道
          "-c:a", "pcm_s16le", # PCM 编码，精准切割
          temp_path
      ], check=True)
      ```
  - 添加日志记录（使用 Python `logging`）

- [ ] **实现虚拟分段转录逻辑**：创建 `backend/app/services/transcription_service.py`
  - 实现 `segment_and_transcribe(episode_id: int)`：
    ```python
    # Step 1: 创建虚拟分段
    num_segments = math.ceil(episode.duration / 180)
    for i in range(num_segments):
        AudioSegment(
            episode_id=episode.id,
            segment_index=i,
            segment_id=f"segment_{i+1:03d}",
            segment_path=None,  # 虚拟分段
            start_time=i * 180,
            end_time=min((i + 1) * 180, episode.duration),
            status="pending"
        )
    
    # Step 2: 按顺序转录每个虚拟分段
    for segment in episode.segments:
        await transcribe_virtual_segment(segment)
    ```
  - 实现 `transcribe_virtual_segment(segment: AudioSegment)`：
    ```python
    # 提取片段到临时文件（WAV 格式，精准切割）
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp:  # 改为 WAV
        # ⚠️ 使用正确的 FFmpeg 参数
        subprocess.run([
            "ffmpeg", "-y",
            "-i", episode.audio_path,
            "-ss", str(segment.start_time),
            "-t", str(segment.duration),
            "-ar", "16000",      # Whisper 需要 16kHz
            "-ac", "1",          # 单声道
            "-c:a", "pcm_s16le", # PCM 编码，精准切割
            temp.name
        ], check=True)
        
        # 转录临时文件
        cues = whisper_service.transcribe(temp.name)
        # 保存 TranscriptCue 到数据库
        save_cues_to_db(cues, segment)
    # 临时文件自动删除
    ```

- [ ] **异步任务队列**
  - 使用 FastAPI `BackgroundTasks` 处理转录
  - 转录期间更新 `Episode.transcription_status` 为 `processing`
  - 更新 `Episode.transcription_progress`（百分比）
  - 转录完成后更新为 `completed`，失败则更新为 `failed`
  - 支持暂停/恢复识别（记录当前 segment）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 转录一个 5 分钟音频 < 2 分钟
  - [ ] 转录过程中 API 不阻塞
  - [ ] 生成的 TranscriptCue 包含准确的时间戳和 speaker
  - [ ] **时间戳精度测试**（Critical ⚠️）：
    - 手动在音频中找一个明确的声音（如 "hello"）
    - 验证 Whisper 返回的 `start_time` 与实际音频时间偏差 < 0.5 秒
    - 验证跨段字幕时间连续性（segment_001 最后一句和 segment_002 第一句无重叠）
  - [ ] 临时文件在转录完成后自动删除
  - [ ] 存储占用验证：只有一份完整音频（无分段文件）
  - [ ] FFmpeg 提取性能测试：3 分钟片段转码 < 2 秒（PCM 编码）

---

#### Task 1.3：Episode 管理 API（含文件去重）
**优先级**: P0  
**预计工时**: 8 小时（新增文件去重和 MD5 计算）

- [ ] **测试先行**：编写 `backend/tests/test_episode_api.py`
  - 测试上传音频文件（`multipart/form-data`）
  - 测试文件去重：
    - 上传相同文件两次 → 返回已存在的 Episode
    - 验证 `file_hash` 唯一性
  - **测试异步 MD5 计算**（Critical ⚠️）：
    - 模拟同时上传多个文件（并发请求）
    - 验证计算 MD5 期间，其他 API 请求（如 `GET /episodes`）仍能正常响应
    - 验证响应时间：其他请求延迟 < 100ms（不被 MD5 计算阻塞）
  - 测试创建 Episode（验证数据库记录）
  - 测试触发 Whisper 转录（验证状态变更）
  - 测试查询 Episode 列表（分页）
  - 测试查询单个 Episode 详情（包含 TranscriptCue）
  - 测试获取转录进度（轮询接口）

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由

  **POST /api/episodes/upload**
  ```python
  # 功能：上传音频文件，创建 Episode，触发异步转录
  # 请求：multipart/form-data (audio_file, title, podcast_id)
  # 响应：{ "episode_id": 1, "status": "processing", "is_duplicate": false }
  
  # 实现逻辑：
  # 1. 计算 MD5 hash（边读边算，节省内存）
  # 2. 检查数据库是否已存在（file_hash）
  # 3. 如果已存在：返回已有的 Episode
  # 4. 如果不存在：
  #    - 保存到 backend/data/audios/{file_hash}.mp3
  #    - 创建 Episode 记录
  #    - 触发异步转录
  ```

  **GET /api/episodes**
  ```python
  # 功能：获取 Episode 列表（支持分页）
  # 参数：?page=1&limit=20&podcast_id=1&status=completed
  # 响应：{ "items": [...], "total": 50, "page": 1, "pages": 3 }
  ```

  **GET /api/episodes/{id}**
  ```python
  # 功能：获取单集详情（包含所有 TranscriptCue）
  # 响应：{
  #   "id": 1,
  #   "title": "...",
  #   "duration": 1800,
  #   "transcription_status": "completed",
  #   "cues": [
  #     { "id": 0, "start": 0.28, "end": 2.22, "speaker": "Lenny", "text": "..." }
  #   ]
  # }
  ```

  **GET /api/episodes/{id}/status**
  ```python
  # 功能：查询转录状态（用于前端轮询）
  # 响应：{
  #   "status": "processing",
  #   "progress": 45.5,
  #   "completed_segments": 5,
  #   "total_segments": 11
  # }
  ```

  **GET /api/episodes/{id}/segments**
  ```python
  # 功能：获取虚拟分段信息（用于调试）
  # 响应：[
  #   { "segment_id": "segment_001", "status": "completed", "cue_count": 15 },
  #   { "segment_id": "segment_002", "status": "processing", "cue_count": 0 }
  # ]
  ```

- [ ] **文件存储逻辑**
  - 实现 `calculate_md5(file: UploadFile) -> str`
    - 边读边算（chunk by chunk），节省内存
    - 使用 `hashlib.md5()`
    - **必须使用 ThreadPoolExecutor 异步执行**（Critical ⚠️）：
      ```python
      import asyncio
      from concurrent.futures import ThreadPoolExecutor
      
      executor = ThreadPoolExecutor()
      
      def calculate_md5_sync(file_path: str) -> str:
          """同步版本的 MD5 计算（在线程池中执行）"""
          hash_md5 = hashlib.md5()
          with open(file_path, "rb") as f:
              for chunk in iter(lambda: f.read(1024 * 1024), b""):  # 1MB chunks
                  hash_md5.update(chunk)
          return hash_md5.hexdigest()
      
      @app.post("/upload")
      async def upload_file(file: UploadFile):
          # Step 1: 先保存到临时文件
          temp_path = f"/tmp/{file.filename}"
          with open(temp_path, "wb") as f:
              shutil.copyfileobj(file.file, f)
          
          # Step 2: 异步计算 MD5（不阻塞其他请求）
          loop = asyncio.get_event_loop()
          file_hash = await loop.run_in_executor(executor, calculate_md5_sync, temp_path)
          
          # Step 3: 移动到最终路径
          final_path = f"backend/data/audios/{file_hash}.mp3"
          shutil.move(temp_path, final_path)
          # ...
      ```
    - **为什么必须用线程池**：
      - Python GIL 限制：即使分块读取，计算密集型任务仍会阻塞主线程
      - 影响：上传大文件时（如 500MB），计算 MD5 需要 20-30 秒，期间其他用户的 API 请求（如获取字幕）会被卡住
      - 解决：`run_in_executor` 将计算扔到线程池，释放主线程
  
  - 音频文件保存到 `backend/data/audios/{file_hash}.mp3`
  - 验证文件大小（< 1GB）
  - 验证文件格式（MP3, WAV）
  - 获取音频时长（使用 `pydub` 或 `ffprobe`）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档自动生成（访问 `/docs`）
  - [ ] 可以通过 Postman 测试上传音频
  - [ ] 文件去重测试通过：相同文件只存储一次
  - [ ] **异步 MD5 测试通过**（Critical ⚠️）：
    - 上传 100MB 文件期间，其他 API 请求（如 `GET /episodes`）响应延迟 < 100ms
    - 并发上传 3 个文件，所有文件都能正常计算 MD5（无死锁）
  - [ ] MD5 计算性能测试：100MB 文件 < 5 秒
  - [ ] 转录进度轮询正常工作

---

### 阶段 2：前端播放器 + 字幕展示（Week 2）

#### Task 2.1：音频播放器组件
**优先级**: P0  
**预计工时**: 6 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/AudioPlayer.test.jsx`
  - 测试组件渲染
  - 测试播放/暂停切换
  - 测试进度条拖动（更新 `currentTime`）
  - 测试音量控制
  - 测试 Hover 状态（按钮背景色变化）
  - 测试 Active 状态（按钮按下效果）

- [ ] **实现组件**：创建 `frontend/src/components/AudioPlayer.jsx`
  - 使用 HTML5 `<audio>` + MUI `Box`/`IconButton` 组件
  - 状态管理：
    - `currentTime`：当前播放时间（秒）
    - `duration`：音频总时长（秒）
    - `isPlaying`：播放状态（布尔值）
    - `volume`：音量（0-1）
  - 实现控制功能：
    - 播放/暂停按钮（PlayArrow / Pause 图标）
    - 进度条（MUI `Slider` 组件）
    - 时间显示（`00:00 / 05:30` 格式）
    - 音量按钮（VolumeUp / VolumeMute 图标）

- [ ] **交互状态验证**（三状态原则）
  - Normal：默认蓝色按钮
  - Hover：背景色加深（`sx={{ '&:hover': { bgcolor: 'primary.dark' } }}`）
  - Active：点击时涟漪效果 + 轻微缩放（`sx={{ '&:active': { transform: 'scale(0.95)' } }}`）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 可以播放测试音频
  - [ ] 拖动进度条实时更新播放位置
  - [ ] 按钮交互流畅（无延迟）

---

#### Task 2.2：实时滚动字幕组件
**优先级**: P0  
**预计工时**: 8 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/TranscriptView.test.jsx`
  - 测试组件渲染（模拟 API 数据）
  - 测试根据 `currentTime` 自动高亮当前字幕
  - 测试点击字幕跳转音频（调用 `onSeek` 回调）
  - 测试自动滚动（当前字幕始终在可视区域）

- [ ] **实现组件**：创建 `frontend/src/components/TranscriptView.jsx`
  - 使用 MUI `List` + `ListItem` 组件
  - Props:
    - `segments`：TranscriptSegment 数组
    - `currentTime`：当前播放时间
    - `onSeek(time)`：点击字幕的回调函数
  - 逻辑实现：
    - 根据 `currentTime` 找到当前激活的 segment（`start_time <= currentTime <= end_time`）
    - 高亮当前 segment（背景色 `bgcolor: 'action.selected'`）
    - 使用 `useRef` + `scrollIntoView` 实现自动滚动
  - 交互实现：
    - 点击任意 segment → 调用 `onSeek(segment.start_time)`

- [ ] **样式优化**
  - 当前字幕：蓝色背景 + 加粗字体
  - 普通字幕：灰色文本
  - Hover 状态：浅灰色背景
  - 间距：每个 segment 之间留 8px 间距

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 字幕随音频实时高亮
  - [ ] 点击字幕后音频跳转成功
  - [ ] 长字幕列表滚动流畅（无卡顿）

---

#### Task 2.3：前后端联调 - Episode 页面
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **创建页面**：`frontend/src/pages/EpisodePage.jsx`
  - 从 URL 参数获取 `episode_id`（使用 React Router）
  - 从 API 获取 Episode 详情（`GET /api/episodes/{id}`）
  - 渲染 AudioPlayer + TranscriptView
  - 实现音频与字幕同步：
    - AudioPlayer 的 `currentTime` → 传递给 TranscriptView
    - TranscriptView 的 `onSeek` → 更新 AudioPlayer 播放位置

- [ ] **状态管理**
  - 使用 `useState` 管理 `episode`, `segments`, `currentTime`
  - 使用 `useEffect` 拉取数据
  - 添加 Loading 状态（MUI `Skeleton` 组件）
  - 添加 Error 状态（MUI `Alert` 组件）

- [ ] **布局设计**
  - 顶部：Episode 标题 + 返回按钮
  - 中间：AudioPlayer（固定在顶部）
  - 底部：TranscriptView（占据剩余空间，可滚动）

- [ ] **验收标准**
  - [ ] 页面正常渲染
  - [ ] 音频播放时字幕同步高亮
  - [ ] 点击字幕后音频跳转
  - [ ] Loading 和 Error 状态正常显示

---

### 阶段 3：划线 + 笔记功能（Week 3）

#### Task 3.1：字幕划线功能（前端）
**优先级**: P0  
**预计工时**: 10 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/HighlightFeature.test.jsx`
  - 测试文本选择（模拟 `mouseup` 事件）
  - 测试划线保存（模拟 API 调用）
  - 测试划线渲染（验证背景色）
  - 测试删除划线

- [ ] **实现划线逻辑**：在 `TranscriptView.jsx` 中添加
  - 监听 `onMouseUp` 事件：
    ```javascript
    const handleMouseUp = () => {
      const selection = window.getSelection();
      if (selection.toString().length > 0) {
        setSelectedText(selection.toString());
        setMenuAnchor({ x: event.clientX, y: event.clientY });
      }
    };
    ```
  - 弹出操作菜单（MUI `Popover` 组件）：
    - 按钮 1：「AI 查询」
    - 按钮 2：「记录想法」
    - 按钮 3：「取消」
  - 点击「记录想法」：
    - 发送 `POST /api/highlights` 保存划线数据
    - 本地更新 UI（在文本上添加背景色）

- [ ] **划线渲染**：
  - 从 API 获取已有的 Highlight 数据（`GET /api/episodes/{id}/highlights`）
  - 在对应的 segment 文本中标记高亮（使用 `<mark>` 标签或 MUI `Box` 包裹）
  - 支持多个划线（不同颜色）

- [ ] **验收标准**
  - [ ] 选中文本后弹出菜单
  - [ ] 点击「记录想法」后文本高亮
  - [ ] 刷新页面后划线保持

---

#### Task 3.2：Highlight API（后端）
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **测试先行**：编写 `backend/tests/test_highlight_api.py`
  - 测试创建划线（验证 `start_offset` 和 `end_offset`）
  - 测试获取划线列表
  - 测试删除划线
  - 测试级联删除：删除 Highlight 时自动删除关联的 Note

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由
  ```python
  # POST /api/highlights
  # 功能：创建划线（支持跨 Cue 划线）
  # 请求：{ 
  #   "episode_id": 1, 
  #   "start_cue_id": 10,  ← 支持跨 Cue！
  #   "end_cue_id": 12,    ← 如果在同一句，则与 start_cue_id 相同
  #   "highlighted_text": "world. This is a test. Thank", 
  #   "start_offset": 6,   # 在起始 cue 中的字符位置
  #   "end_offset": 5,     # 在结束 cue 中的字符位置
  #   "color": "#9C27B0"   # 可选，默认紫色
  # }
  # 响应：{ 
  #   "id": 1, 
  #   "start_cue_id": 10, 
  #   "end_cue_id": 12, 
  #   "color": "#9C27B0", 
  #   "is_cross_cue": true,  # 是否跨 Cue
  #   "created_at": "..." 
  # }

  # GET /api/episodes/{id}/highlights
  # 功能：获取某个 Episode 的所有划线
  # 响应：[ 
  #   { 
  #     "id": 1, 
  #     "start_cue_id": 10, 
  #     "end_cue_id": 10,  # 单句划线
  #     "highlighted_text": "taxonomy", 
  #     "start_offset": 5, 
  #     "end_offset": 13,
  #     "color": "#9C27B0",
  #     "is_cross_cue": false,
  #     "notes": [...]  # 关联的笔记列表（可选）
  #   },
  #   { 
  #     "id": 2, 
  #     "start_cue_id": 10, 
  #     "end_cue_id": 12,  # 跨句划线
  #     "highlighted_text": "world. This is a test. Thank", 
  #     "start_offset": 6, 
  #     "end_offset": 5,
  #     "color": "#9C27B0",
  #     "is_cross_cue": true,
  #     "cue_range": [10, 11, 12]  # 涉及的所有 cue
  #   },
  #   ... 
  # ]

  # DELETE /api/highlights/{id}
  # 响应：{ 
  #   "success": true, 
  #   "deleted_notes_count": 2,
  #   "deleted_ai_queries_count": 1
  # }
  # 说明：删除 Highlight 时会级联删除关联的 Note 和 AIQueryRecord
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档更新
  - [ ] 级联删除测试通过：删除 Highlight 后，关联的 Note 被自动删除

---

#### Task 3.3：笔记双向链接（前端）
**优先级**: P0  
**预计工时**: 12 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/NotePanel.test.jsx`
  - 测试笔记渲染（与划线对齐）
  - 测试笔记滚动跟随
  - 测试点击笔记 → 字幕滚动
  - 测试创建笔记

- [ ] **实现布局**：创建 `frontend/src/components/NotePanel.jsx`
  - 使用 MUI `Grid` 或 `Stack` 实现左右分栏：
    - 左侧（60%）：TranscriptView（带划线）
    - 右侧（40%）：NoteList
  - 使用 `position: sticky` 固定分栏布局

- [ ] **实现「始终跟随划线源」逻辑**
  - 为每个 Highlight 计算其在左侧的垂直位置（`offsetTop`）
  - 在右侧对应位置渲染关联的 Note
  - 监听左侧滚动事件 → 同步右侧笔记位置（使用 `IntersectionObserver`）

- [ ] **实现双向链接**
  - 点击右侧笔记 → 左侧滚动到对应划线 + 高亮划线
  - 点击左侧划线 → 右侧滚动到对应笔记（如果存在）

- [ ] **验收标准**
  - [ ] 笔记与划线源在同一水平线
  - [ ] 滚动时笔记跟随划线移动
  - [ ] 双向点击导航正常工作

---

#### Task 3.4：Note API（后端）
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **测试先行**：编写 `backend/tests/test_note_api.py`
  - 测试创建笔记
  - 测试更新笔记
  - 测试删除笔记
  - 测试获取笔记列表

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由
  ```python
  # POST /api/notes
  # 请求：{ "episode_id": 1, "highlight_id": 5, "content": "...", "note_type": "thought" }
  # 响应：{ "id": 1, "created_at": "..." }

  # PUT /api/notes/{id}
  # 请求：{ "content": "..." }
  # 响应：{ "success": true }

  # DELETE /api/notes/{id}
  # 响应：{ "success": true }

  # GET /api/episodes/{id}/notes
  # 响应：[ { "id": 1, "highlight_id": 5, "content": "...", ... }, ... ]
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档更新

---

### 阶段 4：AI 查询功能（Week 4）

#### Task 4.1：AI 查询服务（后端）
**优先级**: P1（重要）  
**预计工时**: 8 小时

- [ ] **测试先行**：编写 `backend/tests/test_ai_service.py`
  - 测试单词翻译（`query_type: "word_translation"`）
  - 测试短语解释（带上下文）
  - 测试专有名词识别（如 "React", "OpenAI"）
  - 测试错误处理（API 超时、无效响应）

- [ ] **选择 AI API**
  - 方案 A（免费）：Google Translate API（单词翻译）
  - 方案 B（低成本）：OpenAI GPT-3.5-turbo（短语和专有名词）
  - 在 `backend/app/services/ai_service.py` 中实现

- [ ] **实现 AI 查询逻辑**
  ```python
  class AIService:
      def query(self, text: str, context: str, query_type: str) -> str:
          """
          text: 用户划线的文本
          context: 相邻 2-3 个 TranscriptSegment 的文本
          query_type: word_translation / phrase_explanation / concept
          """
          if query_type == "word_translation":
              return self.translate_word(text)
          elif query_type == "phrase_explanation":
              return self.explain_phrase(text, context)
          elif query_type == "concept":
              return self.explain_concept(text, context)
  ```

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由
  ```python
  # POST /api/ai/query
  # 请求：{ "highlight_id": 5, "query_type": "word_translation" }
  # 响应：{ "response": "翻译结果...", "query_id": 1 }
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 单词翻译成功率 > 95%
  - [ ] 短语解释包含上下文理解
  - [ ] API 响应时间 < 3 秒

---

#### Task 4.2：AI 查询界面（前端）
**优先级**: P1  
**预计工时**: 6 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/AIQueryDialog.test.jsx`
  - 测试弹窗打开/关闭
  - 测试 Loading 状态
  - 测试显示 AI 回复
  - 测试「添加到笔记」按钮

- [ ] **实现组件**：创建 `frontend/src/components/AIQueryDialog.jsx`
  - 使用 MUI `Dialog` 组件
  - 内容：
    - 顶部：用户划线的文本（加粗）
    - 中间：AI 回复（使用 `Typography` 组件）
    - 底部：「添加到笔记」按钮 + 「关闭」按钮
  - Loading 状态：显示 `CircularProgress`

- [ ] **集成到划线菜单**
  - 在 `TranscriptView.jsx` 的弹出菜单中添加「AI 查询」按钮
  - 点击后：
    - 发送 `POST /api/ai/query`
    - 打开 AIQueryDialog
    - 显示 Loading → 显示结果

- [ ] **实现「添加到笔记」功能**
  - 点击按钮 → 调用 `POST /api/notes`
  - 自动填充 AI 回复内容
  - 关闭弹窗 → 在右侧笔记列表显示新笔记

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] AI 查询流程流畅（无卡顿）
  - [ ] 添加到笔记后立即显示

---

### 阶段 5：完善与优化（Week 5+）

#### Task 5.1：错误处理与用户反馈
**优先级**: P1  
**预计工时**: 4 小时

- [ ] **后端统一异常处理**
  - 在 `backend/app/main.py` 添加全局异常处理器
  - 对所有 `HTTPException` 返回标准格式：
    ```json
    { "error": "错误信息", "code": "ERROR_CODE", "details": {} }
    ```

- [ ] **前端 Toast 通知**
  - 创建 `frontend/src/components/ToastProvider.jsx`（使用 MUI `Snackbar`）
  - 在所有 API 调用失败时显示 Toast
  - 成功操作也显示提示（如「笔记已保存」）

- [ ] **验收标准**
  - [ ] 所有错误都有友好提示
  - [ ] 无 Silent Failure

---

#### Task 5.2：性能优化
**优先级**: P2（中等）  
**预计工时**: 6 小时

- [ ] **后端优化**
  - 大文件转录采用分片处理（每 5 分钟一个分片）
  - 数据库添加索引：
    - `episodes.podcast_id`
    - `transcript_segments.episode_id`
    - `highlights.segment_id`
    - `notes.highlight_id`

- [ ] **前端优化**
  - 长字幕列表使用虚拟滚动（`react-window`）
  - 划线和笔记数据使用 `useMemo` 缓存
  - 图片懒加载（MUI `LazyLoad`）

- [ ] **验收标准**
  - [ ] 转录 30 分钟音频 < 10 分钟
  - [ ] 渲染 1000+ 字幕片段无卡顿
  - [ ] 内存占用 < 500MB

---

#### Task 5.3：文档更新
**优先级**: P2  
**预计工时**: 2 小时

- [ ] **每个任务完成后更新 `docs/changelog.md`**
  - 格式：`[2025-12-23] [feat] - 实现字幕划线功能 (TranscriptView.jsx, api.py)`

- [ ] **更新 README**
  - 添加项目介绍
  - 添加安装步骤
  - 添加使用说明

- [ ] **API 文档**
  - 访问 `http://localhost:8000/docs` 查看 Swagger 文档
  - 截图保存到 `docs/api_docs.png`

---

## 四、开发节奏

| 周次 | 阶段 | 核心目标 | 产出 |
|------|------|----------|------|
| **Week 1** | 后端数据层 + Whisper | 搭建后端核心功能 | - **8 个数据库表**创建成功<br>- **虚拟分段 + 临时文件转录**实现<br>- **文件去重**（MD5 hash）<br>- Episode 管理 API 完成<br>- 所有后端测试通过 |
| **Week 2** | 前端播放器 + 字幕展示 | 实现音频播放和字幕同步 | - AudioPlayer 组件完成<br>- TranscriptView 组件完成（含 speaker 显示）<br>- EpisodePage 页面完成<br>- 音频与字幕实时同步 |
| **Week 3** | 划线 + 笔记基础功能 | 实现核心交互 | - 字幕划线功能完成<br>- **三种笔记类型**（underline/thought/ai_query）<br>- 笔记创建/编辑/删除完成<br>- 双向链接完成<br>- 笔记与划线源对齐 |
| **Week 4** | AI 查询 + 优化 | 完善 AI 功能 | - AI 查询功能完成<br>- 错误处理完善<br>- 性能优化完成<br>- **MVP 版本发布** |
| **Week 5+** | iPad 适配 + 高级功能 | 跨平台支持 | - 响应式布局完成<br>- Touch 交互优化<br>- 笔记搜索功能<br>- 笔记导出功能 |

---

## 五、关键技术决策

### 5.1 虚拟分段 + 临时文件（存储优化）⭐
**决策**：不物理切割音频文件，只在数据库中记录时间范围，转录时用 FFmpeg 实时提取片段到临时文件  
**理由**：
- 节省 50% 存储空间（只保留一份完整音频）
- 灵活性强：可随时调整分段策略（如改为 5 分钟一段）
- Python `tempfile.NamedTemporaryFile` 自动清理临时文件

**实现**（修正版 ⚠️）：
```python
with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp:
    subprocess.run([
        "ffmpeg", "-y", "-i", audio_path, 
        "-ss", str(start_time), 
        "-t", str(duration),
        # ⚠️ 不使用 -c copy！MP3 只能在关键帧切割，时间戳不精确
        "-ar", "16000",      # Whisper 需要 16kHz
        "-ac", "1",          # 单声道
        "-c:a", "pcm_s16le", # PCM 编码，精准切割
        temp.name
    ], check=True)
    cues = whisper_service.transcribe(temp.name)
# 临时文件自动删除
```

**关键技术修正**（Critical ⚠️）：
- **禁止使用 `-c copy`**：
  - MP3 是压缩格式，只能在关键帧（Keyframe）处切割
  - 如果指定的 `start_time` 不是关键帧，FFmpeg 会寻找最近的关键帧
  - 导致切出的音频有几秒偏差，Whisper 识别的时间戳整体偏移
  - 后果：字幕和音频对不上（严重 Bug）

- **改用 WAV（PCM）格式**：
  - 秒级精准切割（无关键帧限制）
  - Whisper 内部也需要转为 16kHz Mono，提前转码节省加载时间
  - 性能影响：3 分钟片段转码 < 2 秒（完全可接受）

### 5.2 文件去重（MD5 hash + 异步计算）⚠️
**决策**：使用 MD5 hash 标识音频文件，避免重复存储  
**理由**：
- 相同文件只存储一次（节省空间）
- 用户重复上传时直接加载已有数据（提升体验）
- MD5 计算速度快（100MB 文件 < 5 秒）

**实现**（修正版 - 必须异步）：
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor()

def calculate_md5_sync(file_path: str) -> str:
    """同步版本的 MD5 计算（在线程池中执行）"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):  # 1MB chunks
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

@app.post("/upload")
async def upload_file(file: UploadFile):
    # 先保存到临时文件
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        shutil.copyfileobj(file.file, f)
    
    # 异步计算 MD5（不阻塞其他请求）
    loop = asyncio.get_event_loop()
    file_hash = await loop.run_in_executor(executor, calculate_md5_sync, temp_path)
    # ...
```

**关键技术修正**（Critical ⚠️）：
- **必须使用 ThreadPoolExecutor**：
  - 问题：即使分块读取，MD5 计算是 CPU 密集型任务，受 Python GIL 限制
  - 影响：上传 500MB 文件计算 MD5 需要 20-30 秒，期间主线程被阻塞
  - 后果：其他用户的 API 请求（如获取字幕）会被卡住，无响应
  - 解决：`run_in_executor` 将计算扔到线程池，释放主线程处理其他请求

### 5.3 异步转录
**决策**：使用 FastAPI `BackgroundTasks` 处理 Whisper 转录  
**理由**：避免阻塞 API，提升用户体验（前端可以轮询状态）

### 5.4 字幕数据结构（Cue）
**决策**：使用 `TranscriptCue` 表，包含 `speaker` 字段，对应 PRD 的 cue 结构  
**理由**：
- 与 PRD 术语保持一致（cue，不是 segment）
- 支持说话人标识（PRD 必需）
- Whisper 使用 `word_timestamps=True` 提供精准时间戳

### 5.4.1 Episode 表优化（消除数据冗余）⭐ 新增
**决策**：删除 `Episode.show_name` 字段，使用 `@property` 动态获取（方案 1）  
**理由**：
- **消除数据冗余**：`show_name` 与 `Podcast.title` 本质相同，违反 3NF 范式
- **保证数据一致性**：修改 Podcast.title 时无需同步更新所有 Episode
- **简化数据维护**：无需编写同步逻辑
- **性能影响可控**：SQLAlchemy `joinedload` 可避免 N+1 查询，数据量不大时 JOIN 性能可忽略

**实现**：
```python
class Episode(Base):
    podcast = relationship("Podcast", back_populates="episodes")
    
    @property
    def show_name(self):
        """动态获取节目名称"""
        return self.podcast.title if self.podcast else "本地音频"
```

**查询优化**：
```python
# 使用 joinedload 避免 N+1 查询
episodes = db.query(Episode).options(joinedload(Episode.podcast)).all()
for episode in episodes:
    print(episode.show_name)  # 高效访问，无额外查询
```

### 5.4.2 转录状态双层设计（用户体验优化）⭐ 新增
**决策**：删除 Episode 表的转录状态字段，使用 `@property` 分层设计（用户层 + 调试层）  
**理由**：
- **用户体验优先**：隐藏技术细节（分段），只显示结果（进度、剩余时间）
- **关注点分离**：用户看简洁信息，开发者看详细数据
- **保证数据一致性**：Segment 状态为单一数据源
- **符合产品原则**："Don't Make Me Think" - 用户不需要知道"被切成几段"

**用户界面层**（隐藏技术细节）：
```python
episode.transcription_progress          # → 67.0（百分比）
episode.transcription_status_display    # → "正在转录中..."
episode.estimated_time_remaining        # → 90（秒）
```

**开发调试层**（完整技术数据）：
```python
episode.transcription_stats             # → {"total_segments": 4, "completed": 2, ...}
episode.failed_segments_detail          # → [{"segment_id": "002", "error": "..."}]
```

**前端展示示例**：
```javascript
// ✅ 用户看到
<LinearProgress value={episode.transcription_progress} />
<Typography>{episode.transcription_status_display}</Typography>
<Typography>预计还需 {formatTime(episode.estimated_time_remaining)}</Typography>

// 🔧 开发者调试页面看到
<DebugPanel stats={episode.transcription_stats} />
```

### 5.5 笔记类型（三种）
**决策**：`note_type` = `underline`/`thought`/`ai_query`  
**理由**：
- `underline`：纯划线（只有下划线样式，不显示笔记卡片）
- `thought`：用户想法（显示笔记卡片）
- `ai_query`：AI 查询结果（显示笔记卡片）
- 所有笔记都必须关联 `highlight_id`（划线操作）

### 5.6 划线数据结构
**决策**：保存 `start_offset` 和 `end_offset`（相对于 cue 的字符位置）  
**理由**：支持跨段落划线（未来扩展），避免存储重复文本

### 5.7 前端状态管理
**决策**：初期使用 React `useState` + Context，后期考虑 Zustand  
**理由**：快速开发，避免过度设计

### 5.8 AI API 选型
**决策**：
- 单词翻译：Google Translate API（免费）
- 短语解释：OpenAI GPT-3.5-turbo（低成本，约 $0.002/次）
- 专有名词：GPT-3.5-turbo + 上下文注入

**理由**：平衡成本和效果，避免高昂的 GPT-4 费用

### 5.9 数据库选型
**决策**：SQLite（本地文件数据库）  
**理由**：符合「Local-First」理念，无需额外部署数据库服务

### 5.10 测试策略
**决策**：TDD（测试驱动开发）  
**理由**：提前发现 Bug，保证代码质量，便于重构

---

## 附录：Definition of Done（完成标准）

每个任务完成后，必须满足以下标准：

- [ ] **测试通过**：所有单元测试和集成测试为绿色
- [ ] **UI 状态完整**：交互元素有 Normal、Hover、Active 三种状态
- [ ] **错误处理**：无 Silent Failure，用户看到友好提示
- [ ] **代码清理**：无 `console.log`、`print`、注释掉的代码
- [ ] **无硬编码**：魔法数字和 URL 提取到 `constants.py` 或 `config.js`
- [ ] **文档更新**：`docs/changelog.md` 已更新

---

## 结语

本开发计划遵循 **TDD + 迭代式开发 + 用户价值优先** 的原则，确保每个阶段都能产出可用的功能模块。

**下一步行动**：
1. 切换到 Agent 模式
2. 开始执行 **Task 1.1：数据库模型重构**
3. 祝开发顺利！🚀

