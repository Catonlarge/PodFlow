# PodFlow 项目开发计划

> **版本**: v1.0  
> **创建日期**: 2025-12-23  
> **项目目标**: 打造本地优先的 AI 播客学习工具

---

## 目录
- [一、数据库设计方案](#一数据库设计方案)
- [二、开发策略](#二开发策略)
- [三、原子任务拆分](#三原子任务拆分)
- [四、开发节奏](#四开发节奏)
- [五、关键技术决策](#五关键技术决策)

---

## 一、数据库设计方案
表格版本：
https://docs.google.com/document/d/1NFLItC1df_0fSSBD1SvNeDVP0aP3Ap4Gj645jEeMcBU/edit?usp=sharing

### 核心关联关系

```
Podcast (播客) 
  ↓ 1:N
Episode (单集/音频文件)
  ↓ 1:N
AudioSegment (音频虚拟分段) ← 新增！用于异步识别
  ↓ 1:N
TranscriptCue (字幕片段，含 speaker) ← 对应 PRD 的 cue
  ↓ 1:N
Highlight (用户划线)
  ↓ 1:1
Note (笔记：underline/thought/ai_query)
  ↓ 0:1
AIQueryRecord (AI 查询记录)
```

### 文件存储策略

**采用虚拟分段 + 临时文件方案**（存储优化：仅保留一份完整音频）

```
backend/data/
├── audios/                          # 原始完整音频（唯一存储）
│   ├── abc123def456.mp3             # 使用 MD5 hash 命名
│   └── 789ghi012jkl.mp3
└── transcripts/                     # 字幕文件（可选，JSON 格式）
    ├── abc123def456.json            # 全量字幕
    └── abc123def456/
        ├── segment_001.json         # 分段字幕缓存
        └── segment_002.json

说明：
- 不物理切割音频文件（节省 50% 存储空间）
- 转录时用 FFmpeg 提取片段到临时文件（/tmp/）
- 转录完成后自动删除临时文件
```

---

### 数据表设计

#### 1. Podcast（播客）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| title | String | 播客名称（如 "Lenny's Podcast"） |
| source_url | String | 原始链接（用户提供），**唯一索引** ⭐ |
| description | Text | 播客描述 |
| cover_image | String | 封面图片路径 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- 本地音频可不关联 Podcast（`podcast_id` 可为空）
- **`source_url` 唯一性约束**：防止重复添加同一个播客源
- **允许同名 Podcast**：不同源的播客可以有相同的 title（如 "The Daily"）
- **去重逻辑**：添加 Podcast 前，先检查 source_url 是否已存在
- **NULL 值不受限制**：多个 Podcast 可以有 source_url=NULL（手动创建的播客）

**索引优化**：
```sql
CREATE UNIQUE INDEX idx_source_url ON podcasts(source_url);
CREATE INDEX idx_title ON podcasts(title);
```

---

#### 2. Episode（单集/音频文件）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| podcast_id | Integer | 外键 → Podcast（可为空，本地音频无 podcast） |
| **文件信息** | | |
| title | String | 单集标题 |
| original_filename | String | 用户上传的原始文件名 |
| original_path | String | 用户选择的原始路径（仅供参考） |
| audio_path | String | 项目内存储路径（实际使用） |
| file_hash | String | MD5 hash（唯一索引，用于去重） |
| file_size | Integer | 文件大小（字节） |
| duration | Float | 音频总时长（秒） |
| **元数据** | | |
| language | String | 语言代码（默认 "en-US"） |
| created_at | DateTime | 创建时间 |
| updated_at | DateTime | 更新时间 |

**设计要点**：
- `file_hash` 用于去重：相同文件只存储一次
- `audio_path`：保存到项目目录，不依赖用户原始路径
- **存储策略**：只保留完整音频，不切割物理文件
- **❌ 删除分段相关字段**：`needs_segmentation`、`segment_duration`、`total_segments`
  - 理由：这些都是派生属性，改用 `@property` 动态计算
  - `segment_duration` 是全局配置（存储在 `config.py`），不是每个 Episode 独立设置
  - 大多数音频都需要分段，单独存储 `needs_segmentation` 意义不大
  - 便于实验：修改全局配置后，所有 Episode 自动使用新值
- **节目名称优化**（消除数据冗余）：
  - ❌ 删除 `show_name` 字段（避免与 Podcast.title 重复）
  - ✅ 使用 `@property` 动态获取：
    - 如果关联了 Podcast → 返回 `Podcast.title`
    - 如果是本地音频 → 返回 `"本地音频"`
  - ✅ 符合数据库第三范式（3NF），保证数据一致性
  - ✅ 使用 SQLAlchemy `joinedload` 优化查询性能

- **分段信息优化**（全局配置 + 动态计算）⭐ 新增：
  - ❌ 删除字段：`needs_segmentation`、`segment_duration`、`total_segments`
  - ✅ **分段阈值改为全局配置**（`backend/app/config.py`）：
    - `SEGMENT_DURATION = 180`（默认值，可调整）
    - 便于实验：修改配置后，所有 Episode 自动生效
    - 不需要更新数据库，重启服务即可
  - ✅ **使用 `@property` 动态计算**：
    ```python
    @property
    def segment_duration(self):
        """返回全局配置的分段时长"""
        from app.config import SEGMENT_DURATION
        return SEGMENT_DURATION
    
    @property
    def needs_segmentation(self):
        """是否需要分段（基于全局配置）"""
        return self.duration > self.segment_duration
    
    @property
    def total_segments(self):
        """总段数（动态计算）"""
        if not self.needs_segmentation:
            return 1
        import math
        return math.ceil(self.duration / self.segment_duration)
    ```
  - ✅ **设计原则**：
    - 大多数音频都需要分段，单独存储 `needs_segmentation` 没有意义
    - 分段阈值是系统级参数（非用户配置），应集中管理
    - 阈值需要频繁调整以找到最优值（平衡转录速度和用户体验）
    - 消除数据冗余，符合单一数据源原则

- **转录状态优化**（双层设计 - 关注点分离）：
  - ❌ 删除数据库字段：`transcription_status`、`transcription_progress`、`error_message`
  - ✅ **用户界面层**（隐藏技术细节）：
    - `transcription_progress`: 返回百分比（0-100），用于进度条
    - `transcription_status_display`: 返回友好文本（"正在转录中..."/"转录完成"）
    - `estimated_time_remaining`: 返回预计剩余秒数（用户关心"还要等多久"）
    - **不暴露分段信息**：用户不需要知道"被切成几段"
  - ✅ **开发调试层**（完整技术数据）：
    - `transcription_stats`: 返回段数统计（total/completed/failed/processing/pending）
    - `failed_segments_detail`: 返回失败段的详细错误信息
    - **仅供日志、监控、调试使用**
  - ✅ 设计原则：
    - 用户只看到结果（进度、剩余时间），不看到过程（分段）
    - 开发者看到完整数据（段数、错误详情），便于排查问题
    - 数据源单一（Segment 状态为准），保证一致性

- **转录时间戳优化**（从 AudioSegment 聚合计算）⭐ 新增：
  - ❌ 删除数据库字段：`transcription_started_at`、`transcription_completed_at`
  - ✅ **改为 @property 动态计算**：
    - `transcription_started_at` = `min(segment.transcription_started_at)` （第一个开始转录的 Segment）
    - `transcription_completed_at` = `max(segment.recognized_at)` （所有 Segment 完成后才有值）
  - ✅ **理由**：
    - Episode 的时间戳与 AudioSegment 的时间戳存在**严格的逻辑依赖关系**
    - 存储冗余数据会导致**数据不一致风险**（Segment 重试后时间变化，Episode 时间可能未同步）
    - 违反**单一数据源原则**（AudioSegment 才是真实的数据来源）
  - ✅ **优势**：
    - 单一数据源（AudioSegment 为准），无冗余存储
    - 数据一致性保证：Segment 重试后，Episode 时间自动正确
    - 短音频（单 Segment）和长音频（多 Segments）逻辑统一
    - 自动更新：无需手动同步 Episode 和 Segment 的时间戳
  - ✅ **性能考虑**：
    - 使用 `joinedload` 预加载关联，避免 N+1 查询

**索引优化**：
```sql
CREATE UNIQUE INDEX idx_file_hash ON episodes(file_hash);
CREATE INDEX idx_podcast_id ON episodes(podcast_id);
CREATE INDEX idx_title ON episodes(title);
-- ❌ 删除：CREATE INDEX idx_transcription_status（该字段已不存在）
```

---

#### 3. AudioSegment（音频虚拟分段）- 新增！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| **分段信息** | | |
| segment_index | Integer | 段序号（从 0 开始，**用于排序**）⭐ |
| segment_id | String | 分段 ID（如 "segment_001"） |
| segment_path | String | 临时音频文件路径（生命周期管理：pending=NULL / processing=路径 / completed=NULL / failed=保留） |
| **时间范围**（核心） | | |
| start_time | Float | 在原音频中的开始时间（秒） |
| end_time | Float | 在原音频中的结束时间（秒） |
| **识别状态** | | |
| status | String | pending/processing/completed/failed |
| error_message | Text | 错误信息 |
| retry_count | Integer | 重试次数（默认 0）⭐ 新增 |
| transcription_started_at | DateTime | 开始转录时间（用于排序和监控）⭐ 新增 |
| recognized_at | DateTime | 识别完成时间 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- **虚拟分段**：只记录时间范围（`start_time`, `end_time`），不切割物理文件
- **❌ 删除 duration 字段**：改为 `@property` 动态计算（`end_time - start_time`），避免数据不一致
- **临时文件生命周期管理**（`segment_path` 字段优化）：
  - **初始状态（pending）**：`segment_path = NULL`（未提取音频）
  - **转录开始**：FFmpeg 提取片段到持久临时文件（如 `backend/data/temp_segments/segment_001_abc123.wav`），记录路径到 `segment_path`
  - **转录成功（completed）**：删除临时文件，清空 `segment_path = NULL`
  - **转录失败（failed）**：保留临时文件和路径，重试时可直接使用（节省提取时间）
  - **定期清理**：孤儿临时文件（超过 24 小时的失败转录）由后台任务清理
- **中断恢复**：服务器重启后，可根据 `segment_path` 继续转录（如果文件存在）
- **支持异步识别**：用户滚动时按需识别后续 segment
- **顺序保证**：`segment_index` 必须连续（0, 1, 2, 3...），用于保证分段顺序
- **重试机制**：`retry_count` 记录失败重试次数，便于监控和限制最大重试
- **删除冗余字段**：`cue_count` 删除（从 TranscriptCue 关联查询即可）、`duration` 删除（动态计算）

**索引优化**：
```sql
-- 按 episode 和 segment_index 排序（保证顺序）
CREATE INDEX idx_episode_segment ON audio_segments(episode_id, segment_index);
-- 按状态查询（用于监控和重试）
CREATE INDEX idx_segment_status ON audio_segments(status);
-- 复合索引（用于查询某个 episode 的待处理 segment）
CREATE INDEX idx_episode_status_segment ON audio_segments(episode_id, status, segment_index);
```

---

#### 4. TranscriptCue（字幕片段）- 重命名！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| segment_id | Integer | 外键 → AudioSegment（可选） |
| **字幕内容**（对应 PRD 的 cue 结构） | | |
| cue_index | Integer | Episode 级别的全局索引（1, 2, 3...） ← 重命名！ |
| start_time | Float | 开始时间戳（秒） |
| end_time | Float | 结束时间戳（秒） |
| speaker | String | 说话人（如 "Lenny", "SPEAKER_01", "Unknown"） |
| text | Text | 字幕文本 |
| created_at | DateTime | 创建时间 |

**设计要点**：
- 对应 PRD 中的 `cue` 概念（不是 segment）
- `speaker` 字段：支持说话人标识（PRD 必需），默认 "Unknown"
- **`cue_index`**：Episode 级别的全局索引（⭐ 最终方案：保留 + 重新索引）
  - **存储为数据库字段**：保证全局连续性（1, 2, 3, 4...）
  - **分配时机**：每当某个 segment 转录完成时，统一重新计算所有 cue 的 `cue_index`
  - **重新索引策略**（Critical ⭐⭐⭐）：
    ```python
    # 核心原则：cue_index 必须全局连续，按 start_time 排序
    def save_cues_to_db(cues, segment, db):
        # 1. 保存新 cue（先不分配 cue_index）
        new_cues = [
            TranscriptCue(
                episode_id=segment.episode_id,
                segment_id=segment.id,
                start_time=cue["start"] + segment.start_time,  # 绝对时间
                end_time=cue["end"] + segment.start_time,
                speaker=cue.get("speaker", "Unknown"),
                text=cue["text"],
                cue_index=0  # 临时值
            )
            for cue in cues
        ]
        db.add_all(new_cues)
        db.flush()  # 获取 ID
        
        # 2. 重新索引：查询该 Episode 的所有 cue，按 start_time 排序
        all_cues = db.query(TranscriptCue).filter(
            TranscriptCue.episode_id == segment.episode_id
        ).order_by(TranscriptCue.start_time).all()
        
        # 3. 统一分配连续的 cue_index
        for index, cue in enumerate(all_cues, start=1):
            cue.cue_index = index  # 1, 2, 3, 4...
        
        db.commit()
    ```
  - **异步转录场景**：
    - segment_002 先完成 → 生成 cue，分配 cue_index（如 1, 2, 3）
    - segment_001 后完成 → 生成 cue，**重新索引所有 cue**（如 1-8 是 segment_001，9-11 是 segment_002）
    - 结果：`cue_index` 全局连续，按时间顺序正确
  - **失败与重试处理**：
    - segment_001 失败 → 不生成 cue，其他 segment 正常分配 cue_index
    - segment_001 重试成功 → 生成 cue，**重新索引所有 cue**
  - **用户体验**：完全无感知，字幕和笔记始终按顺序展示
- **`start_time`/`end_time`**：相对于原始音频的绝对时间（⭐ 排序依据）
  - 这是保证字幕顺序的核心字段
  - `cue_index` 的分配完全基于 `start_time` 排序
  - 查询时可以使用 `ORDER BY cue_index`（性能更好）或 `ORDER BY start_time`（语义更清晰）
- **Highlight 关联**：使用 `cue.id`（主键），不使用 cue_index（⭐ Critical）
  - `cue.id` 是自增主键，一旦分配永不改变
  - 即使 `cue_index` 重新分配，Highlight 仍然关联正确的 cue
  - 完全解决异步转录的关联问题

**PRD 字幕格式对应**：
```json
{
  "cues": [
    {
      "id": 0,                      → cue_index（从 1 开始更直观）
      "start": 0.28,                → start_time
      "end": 2.22,                  → end_time
      "speaker": "Lenny",           → speaker
      "text": "Thank you..."        → text
    }
  ]
}
```

**索引优化**：
```sql
-- Episode 级别的全局索引（用于快速排序和范围查询）⭐ 主要查询索引
CREATE INDEX idx_episode_cue_index ON transcript_cues(episode_id, cue_index);
-- 时间范围索引（用于音频同步和重新索引）
CREATE INDEX idx_episode_time ON transcript_cues(episode_id, start_time);
-- Segment 关联索引（用于异步识别）
CREATE INDEX idx_segment_cue ON transcript_cues(segment_id);
```

---

#### 5. Highlight（用户划线）- 简化设计：单 cue 关联 + 分组管理 ⭐
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| **划线范围**（单 cue 关联）⭐ 简化 | | |
| cue_id | Integer | 外键 → TranscriptCue（只关联一个 cue）⭐ |
| start_offset | Integer | 在 cue 内的字符起始位置 |
| end_offset | Integer | 在 cue 内的字符结束位置 |
| **划线内容**（快照） | | |
| highlighted_text | Text | 被划线的文本内容（用于快速渲染） |
| **分组管理**（跨 cue 划线支持）⭐ 新增 | | |
| highlight_group_id | String | 分组 ID（UUID），同一次划线产生的多个 Highlight 共享 |
| **样式** | | |
| color | String | 划线颜色（默认 #9C27B0，紫色） |
| created_at | DateTime | 创建时间 |

**设计要点**（Critical ⭐⭐⭐ - 简化设计，解决异步转录问题）：
- **核心变更**：不允许单个 Highlight 跨 cue，改为自动拆分 + 分组管理
- **用户体验**：
  - 用户划线时可以跨 cue（如跨多个句子）
  - 前端自动拆分成多个 Highlight（每个 cue 一个）
  - 使用 `highlight_group_id` 关联同一次划线产生的多个 Highlight
  - 用户完全无感知，看到的仍然是连续的高亮
- **实现逻辑**：
  ```javascript
  // 前端划线逻辑
  function handleTextSelection(selection) {
      const affectedCues = getAffectedCues(selection);
      
      if (affectedCues.length === 1) {
          // 单 cue 划线（90% 的情况）
          createHighlight({
              cue_id: affectedCues[0].id,
              start_offset: selection.startOffset,
              end_offset: selection.endOffset,
              highlight_group_id: null  // 单 cue 不需要分组
          });
      } else {
          // 跨 cue 划线（10% 的情况）
          const groupId = generateUUID();
          affectedCues.forEach((cue, index) => {
              createHighlight({
                  cue_id: cue.id,
                  start_offset: index === 0 ? selection.startOffset : 0,
                  end_offset: index === affectedCues.length - 1 ? selection.endOffset : cue.text.length,
                  highlight_group_id: groupId  // ⭐ 同一组
              });
          });
      }
  }
  ```
- **删除逻辑**：
  ```python
  # 删除 Highlight 时，按组删除
  if highlight.highlight_group_id:
      db.query(Highlight).filter(
          Highlight.highlight_group_id == highlight.highlight_group_id
      ).delete()
  else:
      db.delete(highlight)
  ```
- **优点**：
  - ✅ 极大简化设计：每个 Highlight 只关联一个 cue
  - ✅ 完全解决 cue_index 变化问题：使用 `cue.id`（主键）关联，永不变化
  - ✅ 前端渲染简单：每个 cue 独立渲染高亮
  - ✅ 符合 90% 的实际使用场景（单词/句子划线）
  - ✅ 通过分组管理仍然支持跨 cue 划线（用户无感知）
- **颜色默认紫色**（PRD 318行："被划线的字幕出现紫色下划线"）

**索引优化**：
```sql
-- Episode 级别的划线查询
CREATE INDEX idx_episode_highlight ON highlights(episode_id);
-- Cue 级别的划线查询（高频）
CREATE INDEX idx_highlight_cue ON highlights(cue_id);
-- 分组查询（用于按组删除和渲染）⭐ 新增
CREATE INDEX idx_highlight_group ON highlights(highlight_group_id);
-- 复合索引（提高查询性能）
CREATE INDEX idx_highlight_episode_cue ON highlights(episode_id, cue_id);
```

---

#### 6. Note（笔记）- 明确 AI 查询转化关系！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| episode_id | Integer | 外键 → Episode |
| highlight_id | Integer | 外键 → Highlight（必需） |
| **来源追踪** ← 新增！ | | |
| origin_ai_query_id | Integer | 外键 → AIQueryRecord（可选，标记来源） |
| **笔记内容** | | |
| content | Text | 笔记内容（underline 类型时为空） |
| note_type | String | underline/thought/ai_card ← 修正！ |
| **元数据** | | |
| created_at | DateTime | 创建时间 |
| updated_at | DateTime | 更新时间 |

**设计要点**（Critical - AI 查询与笔记的转化关系）：
- **`note_type` 三种类型**：
  - `underline`：纯划线（只有下划线样式，不显示笔记卡片，content 为空）
  - `thought`：用户想法（显示笔记卡片，用户手动输入）
  - **`ai_card`**：保存的 AI 查询结果（显示笔记卡片，来自 AI）← 修正命名！
  
- **AI 查询到笔记的转化逻辑**（PRD 6.2.4.e）：
  1. 用户划线 → 点击"AI 查询" → 创建 `AIQueryRecord`（临时）
  2. AI 返回结果 → 前端展示"AI查询卡片"（临时 UI）
  3. 用户点击卡片上的"笔记图标" → 创建 `Note`（持久化）：
     - `note_type = 'ai_card'`
     - `content = AIQueryRecord.response`
     - `origin_ai_query_id = AIQueryRecord.id`（记录来源）
  4. 右侧笔记栏渲染所有 `Note` 表数据（不包括未保存的 AI 查询）

- **`origin_ai_query_id` 的作用**：
  - 追溯笔记来源：这条笔记是从哪次 AI 查询保存的
  - 避免重复查询：用户再次划同样的内容，可以直接从 `AIQueryRecord` 缓存加载
  - 数据分析：统计用户最常查询的词汇/短语

- **`highlight_id` 必需**：所有笔记都源于划线操作

- **笔记位置动态计算**：通过 `Note → Highlight → TranscriptCue` 关联链，在前端根据 Cue 的 DOM 位置（`offsetTop`）动态渲染笔记卡片（PRD 390行："笔记卡片的顶部在用户的'划线源'顶部上面24px的位置"）

**索引优化**：
```sql
-- 基础索引
CREATE INDEX idx_episode_note ON notes(episode_id);
CREATE INDEX idx_highlight_note ON notes(highlight_id);
CREATE INDEX idx_note_type ON notes(note_type);
CREATE INDEX idx_origin_ai_query ON notes(origin_ai_query_id);
-- 复合索引（提高查询性能）
CREATE INDEX idx_note_episode_type ON notes(episode_id, note_type);
CREATE INDEX idx_note_episode_highlight ON notes(episode_id, highlight_id);
```

---

#### 7. AIQueryRecord（AI 查询记录）- 作为缓存/日志！
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| highlight_id | Integer | 外键 → Highlight（必需） |
| **查询内容** | | |
| query_text | Text | 用户查询的文本（划线内容） |
| context_text | Text | 上下文（相邻 2-3 个 cue 的文本） ← 重命名！ |
| response_text | Text | AI 返回的结果 ← 重命名！ |
| **查询类型和提供商** | | |
| query_type | String | word_translation/phrase_explanation/concept |
| provider | String | AI 提供商（如 "gpt-3.5", "google"） ← 新增！ |
| **状态** | | |
| status | String | processing/completed/failed |
| created_at | DateTime | 创建时间 |

**设计要点**（Critical - AI 查询作为缓存/日志）：
- **AIQueryRecord 的定位**：
  - **缓存**：避免重复查询同样的内容（节省 Token 成本）
  - **日志**：记录所有 AI 查询历史，用于数据分析
  - **临时存储**：用户可能查询了但没有保存为笔记

- **独立存在，不强依赖 Note**：
  - 用户划线 → 点"AI 查询" → 立即创建 `AIQueryRecord`
  - 用户可能不保存为笔记（只是临时查看）
  - 如果保存为笔记，Note 通过 `origin_ai_query_id` 反向关联

- **查询缓存逻辑**：
  ```python
  # 用户划线查询前，先检查是否已有缓存
  existing = db.query(AIQueryRecord).filter(
      AIQueryRecord.highlight_id == highlight.id,
      AIQueryRecord.query_type == "word_translation"
  ).first()
  
  if existing and existing.status == "completed":
      return existing.response_text  # 直接返回缓存
  else:
      # 调用 AI API
      response = ai_service.query(...)
      # 保存新记录
  ```

- **`context_text` 的构建**：包含相邻 2-3 个 TranscriptCue 的文本，用于专有名词识别
- **`provider` 字段**：标记 AI 提供商，便于后续分析不同模型的效果

**反向关联**：
- `AIQueryRecord` → 可能被多个 `Note` 引用（`origin_ai_query_id`）
- 但删除 `AIQueryRecord` 不会删除 `Note`（Note 已经保存了 content）

---

#### 8. Vocabulary（生词本）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | Integer | 主键 |
| word | String | 单词（索引） |
| definition | Text | 释义 |
| episode_id | Integer | 外键 → Episode |
| highlight_id | Integer | 外键 → Highlight（可选） |
| created_at | DateTime | 创建时间 |

---

### 级联删除规则（Critical）

**为什么需要级联删除**：
- PRD 326行："删除包括：笔记卡片、下划线效果、本地json数据"
- 保证数据一致性：删除父记录时自动清理所有关联的子记录
- 避免孤儿数据：防止数据库中出现无效的外键引用

**SQLAlchemy 实现**：

```python
# Episode 被删除 → 级联删除所有关联数据
class Episode(Base):
    segments = relationship("AudioSegment", back_populates="episode", cascade="all, delete-orphan")
    cues = relationship("TranscriptCue", back_populates="episode", cascade="all, delete-orphan")
    highlights = relationship("Highlight", back_populates="episode", cascade="all, delete-orphan")
    notes = relationship("Note", back_populates="episode", cascade="all, delete-orphan")
    vocabulary = relationship("Vocabulary", back_populates="episode", cascade="all, delete-orphan")

# Highlight 被删除 → 级联删除关联的 Note 和 AIQueryRecord
class Highlight(Base):
    # 简化设计：只关联一个 cue（⭐ 修改）
    cue = relationship("TranscriptCue", foreign_keys="Highlight.cue_id")
    
    # 分组管理（⭐ 新增）
    highlight_group_id = Column(String, nullable=True, index=True)
    
    # 级联删除
    notes = relationship("Note", back_populates="highlight", cascade="all, delete-orphan")
    ai_queries = relationship("AIQueryRecord", back_populates="highlight", cascade="all, delete-orphan")

# Note 不再级联删除 AIQueryRecord（反向关联）
class Note(Base):
    # Note 可能来自 AI 查询，但不拥有它
    origin_ai_query = relationship("AIQueryRecord", foreign_keys="Note.origin_ai_query_id")  # 不级联删除

# AIQueryRecord 独立存在，不依赖 Note
class AIQueryRecord(Base):
    highlight = relationship("Highlight", back_populates="ai_queries")
    # 反向：可能被多个 Note 引用，但不拥有它们

# Podcast 被删除 → Episode 不删除（设置为 NULL）
class Podcast(Base):
    episodes = relationship("Episode", back_populates="podcast")  # 不级联删除

class Episode(Base):
    podcast_id = Column(Integer, ForeignKey("podcasts.id", ondelete="SET NULL"), nullable=True)
```

**级联删除链**（更新）：

```
删除 Episode 
  → 自动删除 AudioSegment
  → 自动删除 TranscriptCue
  → 自动删除 Highlight
    → 自动删除 Note（Note.origin_ai_query_id 仍保留，但不影响）
    → 自动删除 AIQueryRecord
  → 自动删除 Vocabulary

删除 Highlight
  → 自动删除 Note
  → 自动删除 AIQueryRecord

删除 Note
  → **不删除** AIQueryRecord（反向关联，Note 不拥有 AIQueryRecord）

删除 AIQueryRecord
  → **不删除** Note（Note 已经保存了 content，origin_ai_query_id 只是标记来源）

删除 Podcast
  → Episode 的 podcast_id 设置为 NULL（保留本地音频）
```

**关键变化**：
- `Note` 和 `AIQueryRecord` 的关系改为**反向关联**（Note 引用 AIQueryRecord，但不拥有它）
- 删除 `AIQueryRecord` 不会影响 `Note`（笔记已持久化）
- 删除 `Note` 不会影响 `AIQueryRecord`（查询记录作为缓存/日志保留）

**测试用例**（Task 1.1 必须包含）：

```python
def test_cascade_delete_episode(db):
    """测试删除 Episode 时级联删除所有关联数据"""
    episode = create_test_episode()
    segment = create_test_segment(episode.id)
    cue = create_test_cue(episode.id, segment.id)
    highlight = create_test_highlight(episode.id, cue.id, cue.id)  # 单句划线
    note = create_test_note(episode.id, highlight.id)
    ai_query = create_test_ai_query(highlight.id)
    
    # 删除 Episode
    db.delete(episode)
    db.commit()
    
    # 验证所有关联数据被删除
    assert db.query(AudioSegment).filter_by(episode_id=episode.id).count() == 0
    assert db.query(TranscriptCue).filter_by(episode_id=episode.id).count() == 0
    assert db.query(Highlight).filter_by(episode_id=episode.id).count() == 0
    assert db.query(Note).filter_by(episode_id=episode.id).count() == 0
    assert db.query(AIQueryRecord).filter_by(highlight_id=highlight.id).count() == 0


def test_single_cue_highlight(db):
    """测试单 cue 划线（90% 场景）⭐ 修改"""
    episode = create_test_episode()
    cue = create_test_cue(episode.id, text="Hello world.")
    
    # 创建单 cue 划线（划 "world"）
    highlight = Highlight(
        episode_id=episode.id,
        cue_id=cue.id,  # ⭐ 只关联一个 cue
        start_offset=6,
        end_offset=11,
        highlighted_text="world",
        highlight_group_id=None,  # 单 cue 不需要分组
        color="#9C27B0"
    )
    db.add(highlight)
    db.commit()
    
    # 验证关联
    assert highlight.cue_id == cue.id
    assert highlight.highlight_group_id is None


def test_cross_cue_highlight_with_grouping(db):
    """测试跨 cue 划线（自动拆分 + 分组管理）⭐ 新增"""
    episode = create_test_episode()
    cue1 = create_test_cue(episode.id, text="Hello world.")
    cue2 = create_test_cue(episode.id, text="This is a test.")
    cue3 = create_test_cue(episode.id, text="Thank you.")
    
    # 用户跨 cue 划线 → 自动拆分成 3 个 Highlight
    group_id = "uuid-12345"
    
    highlight1 = Highlight(
        episode_id=episode.id,
        cue_id=cue1.id,
        start_offset=6,
        end_offset=12,  # "world." 到末尾
        highlighted_text="world.",
        highlight_group_id=group_id,
        color="#9C27B0"
    )
    
    highlight2 = Highlight(
        episode_id=episode.id,
        cue_id=cue2.id,
        start_offset=0,
        end_offset=15,  # 完整 cue
        highlighted_text="This is a test.",
        highlight_group_id=group_id,
        color="#9C27B0"
    )
    
    highlight3 = Highlight(
        episode_id=episode.id,
        cue_id=cue3.id,
        start_offset=0,
        end_offset=5,  # "Thank"
        highlighted_text="Thank",
        highlight_group_id=group_id,
        color="#9C27B0"
    )
    
    db.add_all([highlight1, highlight2, highlight3])
    db.commit()
    
    # 验证分组
    highlights = db.query(Highlight).filter(
        Highlight.highlight_group_id == group_id
    ).all()
    assert len(highlights) == 3
    
    # 验证按组删除
    db.query(Highlight).filter(
        Highlight.highlight_group_id == group_id
    ).delete()
    db.commit()
    
    assert db.query(Highlight).count() == 0


def test_ai_query_to_note_conversion(db):
    """测试 AI 查询转笔记的逻辑（Critical）"""
    episode = create_test_episode()
    cue = create_test_cue(episode.id, cue_index=1)
    highlight = create_test_highlight(episode.id, cue.id, cue.id)
    
    # 1. 用户划线 → AI 查询
    ai_query = AIQueryRecord(
        highlight_id=highlight.id,
        query_text="taxonomy",
        context_text="...",
        response_text="n. 分类学；分类法",
        query_type="word_translation",
        provider="gpt-3.5",
        status="completed"
    )
    db.add(ai_query)
    db.commit()
    
    # 2. 用户点击"保存笔记" → 创建 Note
    note = Note(
        episode_id=episode.id,
        highlight_id=highlight.id,
        origin_ai_query_id=ai_query.id,  # 标记来源
        content=ai_query.response_text,
        note_type="ai_card"
    )
    db.add(note)
    db.commit()
    
    # 验证关联
    assert note.origin_ai_query_id == ai_query.id
    assert note.note_type == "ai_card"
    
    # 3. 删除 AIQueryRecord → Note 保留
    db.delete(ai_query)
    db.commit()
    
    assert db.query(Note).filter_by(id=note.id).count() == 1  # Note 仍存在
    assert note.origin_ai_query_id == ai_query.id  # 外键保留（但记录已不存在）


def test_episode_show_name_property(db):
    """测试 Episode 的 show_name 属性（方案 1 优化）"""
    # 1. 创建关联 Podcast 的 Episode
    podcast = Podcast(title="Lenny's Podcast")
    db.add(podcast)
    db.commit()
    
    episode_with_podcast = Episode(
        title="Episode 1",
        podcast_id=podcast.id,
        file_hash="hash001"
    )
    db.add(episode_with_podcast)
    db.commit()
    
    # 验证 show_name 从 Podcast 获取
    assert episode_with_podcast.show_name == "Lenny's Podcast"
    assert episode_with_podcast.show_name == podcast.title
    
    # 2. 创建本地音频（无 Podcast）
    local_episode = Episode(
        title="Local Audio",
        podcast_id=None,
        file_hash="hash002"
    )
    db.add(local_episode)
    db.commit()
    
    # 验证 show_name 返回默认值
    assert local_episode.show_name == "本地音频"
    
    # 3. 使用 joinedload 优化查询（避免 N+1 问题）
    from sqlalchemy.orm import joinedload
    
    episodes = db.query(Episode).options(joinedload(Episode.podcast)).all()
    
    # 访问 show_name 不会触发额外查询
    for ep in episodes:
        _ = ep.show_name  # 高效访问
    
    assert len(episodes) == 2
```

---

### 存储优化策略总结

| 方案 | 存储占用 | 实现复杂度 | 采用 |
|------|---------|-----------|-----|
| 物理分段（切割文件） | 200% | 简单 | ❌ |
| **虚拟分段（临时文件）** | **100%** | **简单** | **✅** |
| 符号链接 | 100% | 复杂 | ❌ |

**虚拟分段工作流程**（优化版 - 支持中断恢复）：
1. 用户上传音频 → 保存到 `backend/data/audios/{file_hash}.mp3`
2. 创建虚拟分段 → `AudioSegment` 表记录时间范围，`segment_path = NULL`，`status = "pending"`
3. 转录开始 → FFmpeg 提取片段到持久临时文件（`backend/data/temp_segments/segment_001_abc123.wav`）
4. 记录临时文件路径 → 更新 `segment_path`，`status = "processing"`
5. 调用 Whisper 转录临时文件
6. **转录成功** → 删除临时文件，清空 `segment_path = NULL`，`status = "completed"`
7. **转录失败** → 保留临时文件和路径（`segment_path` 不变），`status = "failed"`，重试时直接使用
8. **定期清理** → 后台任务清理超过 24 小时的失败转录临时文件

**关键代码**（优化版 - 支持中断恢复和重试）：
```python
import os

# 1. 检查是否已有临时文件（重试场景）
if segment.segment_path and os.path.exists(segment.segment_path):
    temp_path = segment.segment_path
else:
    # 2. 创建持久临时文件路径
    temp_dir = "backend/data/temp_segments/"
    os.makedirs(temp_dir, exist_ok=True)
    temp_path = f"{temp_dir}segment_{segment.segment_index:03d}_{episode.file_hash}.wav"
    
    # 3. 用 FFmpeg 提取片段并转码为 WAV
    subprocess.run([
        "ffmpeg", "-y",
        "-i", episode.audio_path,
        "-ss", str(segment.start_time),
        "-t", str(segment.duration),
        # 不使用 -c copy！MP3 只能在关键帧切割，会导致时间戳偏移
        "-ar", "16000",      # Whisper 需要 16kHz 采样率
        "-ac", "1",          # 单声道
        "-c:a", "pcm_s16le", # PCM 编码，精准切割（秒级精度）
        temp_path
    ], check=True)
    
    # 4. 记录临时文件路径
    segment.segment_path = temp_path
    segment.status = "processing"
    db.commit()

try:
    # 5. 转录临时文件
    cues = whisper_service.transcribe(temp_path)
    
    # 6. 转录成功，删除临时文件
    os.remove(temp_path)
    segment.segment_path = None
    segment.status = "completed"
    
except Exception as e:
    # 7. 转录失败，保留临时文件和路径（用于重试）
    segment.status = "failed"
    segment.error_message = str(e)
    segment.retry_count += 1
    # segment.segment_path 保留，重试时可直接使用

db.commit()
```

**关键修正说明**：
- ❌ **禁止使用 `-c copy`**：MP3 压缩格式只能在关键帧处切割，时间戳不精确
- ✅ **转码为 WAV（PCM）**：秒级精准切割，且 Whisper 内部也需要转为 16kHz Mono
- ✅ **性能影响可控**：3 分钟片段转码 < 2 秒（完全可接受）

---

## 二、开发策略

### 核心原则：后端优先 + TDD + 前后端并行迭代

#### 为什么后端优先？
1. **数据和逻辑核心**：Whisper 转录、数据库 CRUD、AI 查询都在后端
2. **前端依赖后端 API**：前端组件需要真实数据才能验证交互逻辑
3. **TDD 更容易实施**：后端测试比前端 UI 测试更易编写和验证

#### 开发阶段划分
- **阶段一（后端为主）**：搭建后端核心功能 API + 单元测试
- **阶段二（前后端并行）**：前端消费 API，后端根据前端反馈调整接口
- **阶段三（前端为主）**：UI 交互优化、状态管理、响应式布局

---

## 三、原子任务拆分

### 阶段 1：后端数据层 + Whisper 转录（Week 1）

#### Task 1.1：数据库模型重构
**优先级**: P0（最高）  
**预计工时**: 6 小时（增加了表数量和复杂度）

- [ ] **测试先行**：编写 `backend/tests/test_models_new.py`
  - 测试所有 8 个表创建成功
  - 测试外键关联：
    - Episode → Podcast（可选，ondelete="SET NULL"）
    - AudioSegment → Episode（cascade）
    - TranscriptCue → Episode & AudioSegment（cascade）
    - **Highlight → Episode & TranscriptCue（双外键：start_cue_id, end_cue_id）**
    - Note → Episode & Highlight & AIQueryRecord（origin_ai_query_id）
    - AIQueryRecord → Highlight（cascade）
    - Vocabulary → Episode & Highlight（cascade）
  
  - 测试数据插入和查询
  
  - **测试级联删除**（Critical，对应 PRD 326行）：
    - 删除 Episode → 验证 AudioSegment、TranscriptCue、Highlight、Note、AIQueryRecord、Vocabulary 全部被删除
    - 删除 Highlight → 验证 Note 和 AIQueryRecord 被删除
    - **删除 Note → AIQueryRecord 保留**（反向关联）
    - **删除 AIQueryRecord → Note 保留**（Note 已持久化）
    - 删除 Podcast → 验证 Episode 保留（podcast_id 设为 NULL）
  
  - **测试 Highlight 划线**（Critical，简化设计 ⭐）：
    - 单 cue 划线：`cue_id` 关联单个 cue，`highlight_group_id = None`（90% 场景）
    - 跨 cue 划线：多个 Highlight 共享 `highlight_group_id`（10% 场景）
    - 验证按组删除逻辑：删除一个，同组全删
    - 验证 Highlight 使用 `cue.id`（主键）关联，不使用 cue_index
  
  - **测试 AI 查询到笔记的转化**（Critical）：
    - 创建 AIQueryRecord → 保存为 Note → 验证 `origin_ai_query_id` 关联
    - 删除 AIQueryRecord → 验证 Note 保留
    - 验证 `note_type = 'ai_card'`
  
  - 测试唯一索引：`Episode.file_hash` 唯一性
  - 测试虚拟分段：创建 AudioSegment 时 `segment_path = NULL`
  
  - **测试 AudioSegment 新字段**（⭐ 新增）：
    - AudioSegment 包含 `retry_count` 字段（默认 0）
    - AudioSegment 包含 `transcription_started_at` 字段（用于排序和监控）
    - AudioSegment 不包含 `cue_count` 字段（已删除，冗余）
    - AudioSegment 的 `segment_index` 必须连续（0, 1, 2, 3...），用于保证顺序
    - 测试重试机制：segment 失败后，`retry_count` 正确递增
  
  - **测试新字段**：
    - **TranscriptCue 字段**（⭐ 最终方案）：
      - `cue_index` 是存储字段（Integer，全局连续）
      - 查询时使用 `ORDER BY cue_index` 或 `ORDER BY start_time`
      - 测试 `cue_index` 全局连续性（1, 2, 3, 4...）
      - 测试异步转录场景下的重新索引（Critical ⭐⭐⭐）：
        - segment_002 先完成 → cue_index 为 1, 2, 3
        - segment_001 后完成 → 重新索引后，segment_001 的 cue_index 为 1-8，segment_002 为 9-11
        - 验证 Highlight 仍然关联正确的 cue（使用 cue.id）
    - **Highlight 字段**（⭐ 简化）：
      - 包含 `cue_id` 字段（单 cue 关联）
      - 不包含 `start_cue_id` 和 `end_cue_id` 字段
      - 包含 `highlight_group_id` 字段（UUID，用于跨 cue 划线分组）
      - `color` 默认值为 "#9C27B0"（紫色）
    - **Note 字段**：
      - 包含 `origin_ai_query_id` 字段
      - `note_type` 支持 'underline', 'thought', 'ai_card'
      - 不包含 `position_top` 和 `user_avatar` 字段
    - **AIQueryRecord 字段**：
      - 包含 `provider` 字段
    - **Episode 表优化**（不包含冗余字段）：
      - 不包含 `show_name` 字段（使用 @property 动态获取）
      - `show_name` 属性能正确返回 Podcast.title 或 "本地音频"
      - 不包含 `transcription_status/progress/error_message` 字段（双层设计）
      - 不包含 `needs_segmentation/segment_duration/total_segments` 字段（全局配置 + @property）
      - `needs_segmentation/segment_duration/total_segments` 属性能正确计算
    - **Episode 用户层属性**：
      - `transcription_progress` 返回百分比（0-100）
      - `transcription_status_display` 返回友好文本
      - `estimated_time_remaining` 返回预计剩余秒数
    - **Episode 调试层属性**：
      - `transcription_stats` 返回完整段数统计
      - `failed_segments_detail` 返回失败段详情

- [ ] **实现配置文件**：创建 `backend/app/config.py`
  - 定义全局配置参数：
    ```python
    # 音频分段配置（系统级参数，需要实验找到最优值）
    SEGMENT_DURATION = 180  # 默认 180 秒（3 分钟）
    
    # 说明：
    # - 影响转录速度和内存占用
    # - 太小：分段过多，转录慢
    # - 太大：单段转录时间长，用户等待久
    # - 建议范围：120-300 秒
    ```

- [ ] **实现模型**：重构 `backend/app/models.py`
  - 添加 8 个新表模型：
    1. `Podcast`（播客）
    2. `Episode`（单集，含 file_hash 等）
       - **不包含 show_name 字段**（消除数据冗余）
       - **实现 @property show_name**：动态获取节目名称
       - **不包含 needs_segmentation/segment_duration/total_segments 字段**（全局配置优化）
       - **实现分段相关 @property**（基于全局配置动态计算）：
         
         ```python
         @property
         def segment_duration(self):
             """返回全局配置的分段时长"""
             from app.config import SEGMENT_DURATION
             return SEGMENT_DURATION
         
         @property
         def needs_segmentation(self):
             """是否需要分段（基于全局配置）"""
             return self.duration > self.segment_duration
         
         @property
         def total_segments(self):
             """总段数（动态计算）"""
             if not self.needs_segmentation:
                 return 1
             import math
             return math.ceil(self.duration / self.segment_duration)
         ```
       - **删除转录状态字段**（双层设计优化）
       - **实现转录状态 @property**（用户层 + 调试层）：
         
         ```python
         # ========== 用户界面层（简洁） ==========
         @property
         def transcription_progress(self):
             """返回百分比 0-100（用于进度条）"""
             if not self.segments:
                 return 0.0
             completed = sum(1 for s in self.segments if s.status == "completed")
             return round((completed / len(self.segments)) * 100, 2)
         
         @property
         def transcription_status_display(self):
             """返回友好的状态文本（隐藏技术细节）"""
             status_map = {
                 "pending": "等待转录",
                 "processing": "正在转录中...",
                 "completed": "转录完成",
                 "partial_failed": "部分转录失败，可继续使用",
                 "failed": "转录失败，请重试"
             }
             return status_map.get(self.transcription_status, "未知状态")
         
         @property
         def estimated_time_remaining(self):
             """返回预计剩余秒数（用户关心的信息）"""
             pending = sum(1 for s in self.segments if s.status in ["pending", "processing"])
             return int(pending * 180 * 0.4)  # 每段180s，转录速度0.4x
         
         # ========== 开发调试层（详细） ==========
         @property
         def transcription_stats(self):
             """返回完整的段数统计（仅供调试）"""
             if not self.segments:
                 return {"total_segments": 0, "completed_segments": 0, ...}
             return {
                 "total_segments": len(self.segments),
                 "completed_segments": sum(1 for s in self.segments if s.status == "completed"),
                 "failed_segments": sum(1 for s in self.segments if s.status == "failed"),
                 ...
             }
         
         @property
         def failed_segments_detail(self):
             """返回失败段的详细信息（仅供调试）"""
             return [
                 {"segment_id": s.segment_id, "error_message": s.error_message, ...}
                 for s in self.segments if s.status == "failed"
             ]
         ```
    3. `AudioSegment`（虚拟分段，segment_path 可为空）
    4. **`TranscriptCue`**（字幕片段，含 speaker，cue_index 可选 ⭐ 简化）
    5. **`Highlight`**（用户划线，单 cue 关联 + 分组管理 ⭐ 简化）
       - 只包含 `cue_id`（不包含 start_cue_id/end_cue_id）
       - 包含 `highlight_group_id`（UUID，用于跨 cue 划线分组）
    6. **`Note`**（笔记：underline/thought/ai_card，含 origin_ai_query_id）
    7. **`AIQueryRecord`**（AI 查询记录，含 provider，独立于 Note）
    8. `Vocabulary`（生词本）
  
  - 添加 SQLAlchemy `relationship` 关系映射：
    - **Highlight 的单外键关系**（⭐ 简化）：`cue`（关联单个 TranscriptCue）
    - **分组管理**：`highlight_group_id` 索引（用于按组查询和删除）
    - **Note 的反向关联**：`origin_ai_query`（不拥有 AIQueryRecord）
    - **AIQueryRecord 独立存在**：不被 Note 拥有
  
  - **配置级联删除规则**（Critical）：
    - Episode: `cascade="all, delete-orphan"`
    - Highlight: `cascade="all, delete-orphan"`
    - AIQueryRecord: 由 Highlight 级联删除
    - **Note 不级联删除 AIQueryRecord**（反向关联）
    - Podcast → Episode: `ondelete="SET NULL"`
  
  - 配置外键约束和索引（见数据库设计部分）
  
  - 添加默认值：
    - `TranscriptCue.speaker = "Unknown"`
    - `Highlight.color = "#9C27B0"`（紫色）
    - `AudioSegment.segment_path = None`（虚拟分段）
    - `AIQueryRecord.status = "processing"`

- [ ] **数据库迁移**
  - 删除旧的 `data/podflow.db`（如果存在）
  - 运行 `init_db()` 创建新表
  - 验证表结构（使用 SQLite 客户端查看）
  - 验证索引创建成功

- [ ] **验收标准**
  - [ ] 所有测试用例通过（绿色）
  - [ ] 数据库文件成功创建，包含 8 个表
  - [ ] 可以手动插入测试数据
  - [ ] `Episode.file_hash` 唯一索引生效
  - [ ] 虚拟分段测试通过（segment_path 为 NULL）
  - [ ] **级联删除测试全部通过**（删除父记录时子记录被自动清理）
  - [ ] **Highlight 划线测试通过**（Critical ⭐ 简化）：
    - 单 cue 划线正确创建（90% 场景）
    - 跨 cue 划线自动拆分 + 分组管理（10% 场景）
    - 按组删除正确工作（删除一个，同组全删）
    - Highlight 使用 `cue.id`（主键）关联，不依赖 cue_index
  - [ ] **AI 查询转笔记测试通过**（Critical）：
    - AIQueryRecord 可以转换为 Note
    - 删除 AIQueryRecord 不影响 Note
    - 删除 Note 不影响 AIQueryRecord
  - [ ] 新字段验证通过：
    - **TranscriptCue 字段**（⭐ 简化）：
      - `cue_index` 可选（方案 A 删除，方案 B 保留但允许不连续）
      - 查询使用 `ORDER BY start_time`
    - **Highlight 字段**（⭐ 简化）：
      - 包含 `cue_id` 字段（不包含 start_cue_id/end_cue_id）
      - 包含 `highlight_group_id` 字段（UUID）
      - 默认颜色为紫色（#9C27B0）
    - **Note 字段**：
      - 包含 `origin_ai_query_id` 字段
      - `note_type` 支持 'underline', 'thought', 'ai_card'
      - 不包含 `position_top` 和 `user_avatar` 字段
    - **AIQueryRecord 字段**：
      - 包含 `provider` 字段
  - [ ] **Episode 表优化验证通过**（多项优化）：
    - **节目名称优化**：
      - Episode 表不包含 show_name 字段
      - Episode.show_name @property 能正确返回 Podcast.title
      - 本地音频（podcast_id=None）的 show_name 返回 "本地音频"
    - **分段信息优化**：
      - Episode 表不包含 needs_segmentation/segment_duration/total_segments 字段
      - Episode.segment_duration 返回全局配置值（180）
      - Episode.needs_segmentation 能正确判断（duration > 180）
      - Episode.total_segments 能正确计算（ceil(duration / 180)）
      - 修改全局配置后，属性值自动更新
    - **转录状态优化**：
      - Episode 表不包含 transcription_status/progress/error_message 字段
    - **用户层属性验证**：
      - transcription_progress 返回正确的百分比
      - transcription_status_display 返回友好文本（无技术术语）
      - estimated_time_remaining 计算准确（基于剩余段数）
    - **调试层属性验证**：
      - transcription_stats 返回完整的段数统计
      - failed_segments_detail 返回失败段的详细信息
    - **关注点分离验证**：
      - 用户界面不显示段数信息（隐藏技术细节）
      - 调试界面显示完整数据（便于问题排查）
    - 使用 joinedload 查询时无 N+1 问题
  - [ ] 所有复合索引创建成功

---

#### Task 1.2：Whisper 转录服务实现（虚拟分段 + 临时文件）
**优先级**: P0  
**预计工时**: 10 小时（新增虚拟分段逻辑）

- [ ] **测试先行**：编写 `backend/tests/test_whisper_service.py`
  - 测试音频文件转录（提供测试音频文件 `test.mp3`）
  - 测试时间戳提取（验证 `start_time` 和 `end_time`）
  - 测试 speaker 识别（验证 `speaker` 字段）
  - 测试虚拟分段转录：
    - 用 FFmpeg 提取片段到临时文件
    - 转录完成后临时文件被删除
  - 测试异常处理：
    - 非 MP3 文件 → 返回错误
    - 超大文件（> 1GB） → 返回错误
    - 空文件 → 返回错误
    - FFmpeg 提取失败 → 返回错误

- [ ] **实现 Whisper 服务**：优化 `backend/app/services/whisper_service.py`
  - 实现 `transcribe(audio_path: str) -> List[Dict]`
    - 返回 cue 列表（包含 id, start, end, speaker, text）
    - 使用 Whisper `word_timestamps=True` 获取精准时间戳
    - 识别说话人（WhisperX diarization）
  - 实现 `extract_segment_to_temp(audio_path, start_time, duration) -> str`
    - 用 FFmpeg 提取片段到临时文件（WAV 格式）
    - 使用 `tempfile.NamedTemporaryFile(suffix=".wav")`
    - **修正 FFmpeg 参数**（Critical ⚠️）：
      ```python
      subprocess.run([
          "ffmpeg", "-y",
          "-i", audio_path,
          "-ss", str(start_time),
          "-t", str(duration),
          # ⚠️ 不使用 -c copy！改用精准转码
          "-ar", "16000",      # Whisper 需要 16kHz
          "-ac", "1",          # 单声道
          "-c:a", "pcm_s16le", # PCM 编码，精准切割
          temp_path
      ], check=True)
      ```
  - 添加日志记录（使用 Python `logging`）

- [ ] **实现虚拟分段转录逻辑**：创建 `backend/app/services/transcription_service.py`
  - 实现 `segment_and_transcribe(episode_id: int)`：
    ```python
    # Step 1: 创建虚拟分段
    num_segments = math.ceil(episode.duration / 180)
    for i in range(num_segments):
        AudioSegment(
            episode_id=episode.id,
            segment_index=i,
            segment_id=f"segment_{i+1:03d}",
            segment_path=None,  # 虚拟分段
            start_time=i * 180,
            end_time=min((i + 1) * 180, episode.duration),
            status="pending"
            # duration 通过 @property 动态计算，无需存储
        )
    
    # Step 2: 按顺序转录每个虚拟分段
    for segment in episode.segments:
        await transcribe_virtual_segment(segment)
    ```
  - 实现 `transcribe_virtual_segment(segment: AudioSegment)`（优化版 - 支持中断恢复）：
    ```python
    import os
    
    # 检查是否已有临时文件（重试场景）
    if segment.segment_path and os.path.exists(segment.segment_path):
        temp_path = segment.segment_path
    else:
        # 创建持久临时文件
        temp_dir = "backend/data/temp_segments/"
        os.makedirs(temp_dir, exist_ok=True)
        temp_path = f"{temp_dir}segment_{segment.segment_index:03d}_{episode.file_hash}.wav"
        
        # 提取片段到临时文件（WAV 格式，精准切割）
        subprocess.run([
            "ffmpeg", "-y",
            "-i", episode.audio_path,
            "-ss", str(segment.start_time),
            "-t", str(segment.duration),
            "-ar", "16000",      # Whisper 需要 16kHz
            "-ac", "1",          # 单声道
            "-c:a", "pcm_s16le", # PCM 编码，精准切割
            temp_path
        ], check=True)
    
    # 记录临时文件路径，更新状态
    segment.segment_path = temp_path
    segment.status = "processing"
    segment.transcription_started_at = datetime.utcnow()
    db.commit()
    
    try:
        # 转录临时文件
        cues = whisper_service.transcribe(temp_path)
        
        # 保存 TranscriptCue 到数据库（分配 cue_index）
        save_cues_to_db(cues, segment, db)
        
        # 转录成功，删除临时文件
        os.remove(temp_path)
        segment.segment_path = None
        segment.status = "completed"
        segment.recognized_at = datetime.utcnow()
        db.commit()
        
    except Exception as e:
        # 转录失败，保留临时文件和路径（用于重试）
        segment.status = "failed"
        segment.error_message = str(e)
        segment.retry_count += 1
        db.commit()
        raise
    ```
  
  - 实现 `save_cues_to_db(cues: List[Dict], segment: AudioSegment, db: Session)`（⭐ 最终方案：重新索引）：
    ```python
    """
    保存字幕到数据库并重新索引（保证 cue_index 全局连续）
    
    关键逻辑：
    1. 保存新 cue（先不分配最终的 cue_index）
    2. 查询该 Episode 的所有 cue，按 start_time 排序
    3. 统一重新分配连续的 cue_index（1, 2, 3, 4...）
    4. Highlight 使用 cue.id 关联，不受 cue_index 变化影响
    """
    from sqlalchemy import select
    from datetime import datetime
    
    def save_cues_to_db(cues: List[Dict], segment: AudioSegment, db: Session):
        """保存字幕并重新索引"""
        # Step 1: 创建新 cue（临时 cue_index=0）
        new_cues = []
        for cue_data in cues:
            cue = TranscriptCue(
                episode_id=segment.episode_id,
                segment_id=segment.id,
                start_time=cue_data["start"] + segment.start_time,  # 绝对时间
                end_time=cue_data["end"] + segment.start_time,
                speaker=cue_data.get("speaker", "Unknown"),
                text=cue_data["text"],
                cue_index=0  # 临时值，稍后重新分配
            )
            new_cues.append(cue)
        
        # Step 2: 保存新 cue（获取 ID）
        db.add_all(new_cues)
        db.flush()  # 立即写入数据库，获取自增 ID
        
        # Step 3: 重新索引 - 查询该 Episode 的所有 cue，按 start_time 排序
        all_cues = db.query(TranscriptCue).filter(
            TranscriptCue.episode_id == segment.episode_id
        ).order_by(TranscriptCue.start_time).all()
        
        # Step 4: 统一分配连续的 cue_index
        for index, cue in enumerate(all_cues, start=1):
            cue.cue_index = index  # 1, 2, 3, 4...
        
        # Step 5: 提交事务
        db.commit()
        
        # 返回新创建的 cue 数量
        return len(new_cues)
    ```
  
  - **字幕排序策略说明**（⭐ 最终方案）：
    - **核心原则**：`cue_index` 全局连续（1, 2, 3...），基于 `start_time` 排序
    - **查询逻辑**（两种方式都支持）：
      ```python
      # 方式 1：按 cue_index 排序（性能更好）
      cues = db.query(TranscriptCue).filter(
          TranscriptCue.episode_id == episode_id
      ).order_by(TranscriptCue.cue_index).all()
      
      # 方式 2：按 start_time 排序（语义更清晰）
      cues = db.query(TranscriptCue).filter(
          TranscriptCue.episode_id == episode_id
      ).order_by(TranscriptCue.start_time).all()
      ```
    - **前端显示**：
      ```javascript
      // 直接使用 cue_index（已经是连续的）
      cues.map((cue) => ({
          ...cue,
          displayIndex: cue.cue_index  // 1, 2, 3, 4...
      }))
      ```
    - **Highlight 关联**（Critical ⭐⭐⭐）：
      - 使用 `cue.id`（主键），不使用 cue_index
      - `cue.id` 永不改变，即使 cue_index 重新分配
      - 完全解决异步转录的关联问题
      ```python
      class Highlight(Base):
          cue_id = Column(Integer, ForeignKey("transcript_cues.id"))  # ⭐ 使用主键
          # 查询时通过 cue.id 关联，不受 cue_index 变化影响
      ```
    - **异步转录处理**（详细场景）：
      - **场景 1：顺序转录**
        - segment_001 完成 → 生成 3 个 cue，cue_index = 1, 2, 3
        - segment_002 完成 → 生成 2 个 cue，重新索引后 cue_index = 1, 2, 3, 4, 5
      - **场景 2：乱序转录**
        - segment_002 先完成 → 生成 2 个 cue，cue_index = 1, 2
        - segment_001 后完成 → 生成 3 个 cue，重新索引后 cue_index = 1, 2, 3（segment_001）, 4, 5（segment_002）
      - **场景 3：失败与重试**
        - segment_001 失败 → 不生成 cue
        - segment_002 完成 → 生成 2 个 cue，cue_index = 1, 2
        - segment_001 重试成功 → 生成 3 个 cue，重新索引后 cue_index = 1, 2, 3（segment_001）, 4, 5（segment_002）
    - **失败处理**：
      - segment 失败 → 不创建 cue，cue_index 不占用
      - 其他 segment 不受影响，重新索引时自动连续
    - **并发安全**（Critical ⚠️）：
      - 使用数据库事务保证原子性
      - 重新索引期间，其他请求等待事务完成
      - 建议：在 Episode 级别加锁（悲观锁或乐观锁）

- [ ] **异步任务队列**
  - 使用 FastAPI `BackgroundTasks` 处理转录
  - 转录期间更新 `Episode.transcription_status` 为 `processing`
  - 更新 `Episode.transcription_progress`（百分比）
  - 转录完成后更新为 `completed`，失败则更新为 `failed`
  - 支持暂停/恢复识别（记录当前 segment）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 转录一个 5 分钟音频 < 2 分钟
  - [ ] 转录过程中 API 不阻塞
  - [ ] 生成的 TranscriptCue 包含准确的时间戳和 speaker
  - [ ] **时间戳精度测试**（Critical ⚠️）：
    - 手动在音频中找一个明确的声音（如 "hello"）
    - 验证 Whisper 返回的 `start_time` 与实际音频时间偏差 < 0.5 秒
    - 验证跨段字幕时间连续性（segment_001 最后一句和 segment_002 第一句无重叠）
  - [ ] **cue_index 全局连续性测试**（Critical ⭐⭐⭐）：
    - **测试顺序转录**：
      - segment_001 完成 → 验证 cue_index = 1, 2, 3
      - segment_002 完成 → 验证 cue_index = 1, 2, 3, 4, 5（全局连续）
    - **测试乱序转录**（异步场景）：
      - segment_002 先完成 → 验证 cue_index = 1, 2
      - segment_001 后完成 → 验证重新索引后 cue_index = 1, 2, 3（segment_001）, 4, 5（segment_002）
      - 验证所有 cue_index 全局连续，无跳号
    - **测试失败与重试**：
      - segment_001 失败，segment_002 完成 → 验证 cue_index = 1, 2（segment_002）
      - segment_001 重试成功 → 验证重新索引后 cue_index = 1, 2, 3（segment_001）, 4, 5（segment_002）
    - **测试 Highlight 关联稳定性**（Critical ⭐⭐⭐）：
      - segment_002 先完成，创建 cue（id=10, cue_index=1）
      - 用户在该 cue 上创建 Highlight（cue_id=10）
      - segment_001 后完成，重新索引后该 cue 的 cue_index 变为 4
      - 验证：Highlight 仍然关联 cue_id=10（关联不受影响）
  - [ ] **字幕排序测试**：
    - 验证按 `cue_index` 排序正确（1, 2, 3, 4...）
    - 验证按 `start_time` 排序正确（时间递增）
    - 验证两种排序结果一致
  - [ ] **转录失败处理测试**：
    - 模拟 segment_001 失败，segment_002 成功
    - 验证：segment_001 不创建 TranscriptCue，cue_index 不占用
    - 验证：segment_002 的 cue_index 从 1 开始
  - [ ] **顺序保证测试**：
    - 验证 AudioSegment 的 `segment_index` 连续（0, 1, 2, 3...）
    - 验证 TranscriptCue 的 `cue_index` 连续（1, 2, 3, 4...）
    - 验证 Highlight 使用 `cue.id`（主键）关联，不依赖 cue_index
  - [ ] **重试机制测试**：
    - 模拟 segment 失败后重试成功
    - 验证：`retry_count` 正确递增
    - 验证：重试成功后，cue_index 重新分配，全局连续
  - [ ] **并发安全测试**（可选）：
    - 模拟两个 segment 同时完成（并发调用 save_cues_to_db）
    - 验证：cue_index 无重复，全局连续
    - 验证：数据库事务正确处理并发
  - [ ] 临时文件在转录完成后自动删除
  - [ ] 存储占用验证：只有一份完整音频（无分段文件）
  - [ ] FFmpeg 提取性能测试：3 分钟片段转码 < 2 秒（PCM 编码）

---

#### Task 1.3：Episode 管理 API（含文件去重）
**优先级**: P0  
**预计工时**: 8 小时（新增文件去重和 MD5 计算）

- [ ] **测试先行**：编写 `backend/tests/test_episode_api.py`
  - 测试上传音频文件（`multipart/form-data`）
  - 测试文件去重：
    - 上传相同文件两次 → 返回已存在的 Episode
    - 验证 `file_hash` 唯一性
  - **测试异步 MD5 计算**（Critical ⚠️）：
    - 模拟同时上传多个文件（并发请求）
    - 验证计算 MD5 期间，其他 API 请求（如 `GET /episodes`）仍能正常响应
    - 验证响应时间：其他请求延迟 < 100ms（不被 MD5 计算阻塞）
  - 测试创建 Episode（验证数据库记录）
  - 测试触发 Whisper 转录（验证状态变更）
  - 测试查询 Episode 列表（分页）
  - 测试查询单个 Episode 详情（包含 TranscriptCue）
  - 测试获取转录进度（轮询接口）

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由

  **POST /api/episodes/upload**
  ```python
  # 功能：上传音频文件，创建 Episode，触发异步转录
  # 请求：multipart/form-data (audio_file, title, podcast_id)
  # 响应：{ "episode_id": 1, "status": "processing", "is_duplicate": false }
  
  # 实现逻辑：
  # 1. 计算 MD5 hash（边读边算，节省内存）
  # 2. 检查数据库是否已存在（file_hash）
  # 3. 如果已存在：返回已有的 Episode
  # 4. 如果不存在：
  #    - 保存到 backend/data/audios/{file_hash}.mp3
  #    - 创建 Episode 记录
  #    - 触发异步转录
  ```

  **GET /api/episodes**
  ```python
  # 功能：获取 Episode 列表（支持分页）
  # 参数：?page=1&limit=20&podcast_id=1&status=completed
  # 响应：{ "items": [...], "total": 50, "page": 1, "pages": 3 }
  ```

  **GET /api/episodes/{id}**
  ```python
  # 功能：获取单集详情（包含所有 TranscriptCue）
  # 响应：{
  #   "id": 1,
  #   "title": "...",
  #   "duration": 1800,
  #   "transcription_status": "completed",
  #   "cues": [
  #     { "id": 0, "start": 0.28, "end": 2.22, "speaker": "Lenny", "text": "..." }
  #   ]
  # }
  ```

  **GET /api/episodes/{id}/status**
  ```python
  # 功能：查询转录状态（用于前端轮询）
  # 响应：{
  #   "status": "processing",
  #   "progress": 45.5,
  #   "completed_segments": 5,
  #   "total_segments": 11
  # }
  ```

  **GET /api/episodes/{id}/segments**
  ```python
  # 功能：获取虚拟分段信息（用于调试）
  # 响应：[
  #   { "segment_id": "segment_001", "status": "completed", "cue_count": 15 },
  #   { "segment_id": "segment_002", "status": "processing", "cue_count": 0 }
  # ]
  ```

- [ ] **文件存储逻辑**
  - 实现 `calculate_md5(file: UploadFile) -> str`
    - 边读边算（chunk by chunk），节省内存
    - 使用 `hashlib.md5()`
    - **必须使用 ThreadPoolExecutor 异步执行**（Critical ⚠️）：
      ```python
      import asyncio
      from concurrent.futures import ThreadPoolExecutor
      
      executor = ThreadPoolExecutor()
      
      def calculate_md5_sync(file_path: str) -> str:
          """同步版本的 MD5 计算（在线程池中执行）"""
          hash_md5 = hashlib.md5()
          with open(file_path, "rb") as f:
              for chunk in iter(lambda: f.read(1024 * 1024), b""):  # 1MB chunks
                  hash_md5.update(chunk)
          return hash_md5.hexdigest()
      
      @app.post("/upload")
      async def upload_file(file: UploadFile):
          # Step 1: 先保存到临时文件
          temp_path = f"/tmp/{file.filename}"
          with open(temp_path, "wb") as f:
              shutil.copyfileobj(file.file, f)
          
          # Step 2: 异步计算 MD5（不阻塞其他请求）
          loop = asyncio.get_event_loop()
          file_hash = await loop.run_in_executor(executor, calculate_md5_sync, temp_path)
          
          # Step 3: 移动到最终路径
          final_path = f"backend/data/audios/{file_hash}.mp3"
          shutil.move(temp_path, final_path)
          # ...
      ```
    - **为什么必须用线程池**：
      - Python GIL 限制：即使分块读取，计算密集型任务仍会阻塞主线程
      - 影响：上传大文件时（如 500MB），计算 MD5 需要 20-30 秒，期间其他用户的 API 请求（如获取字幕）会被卡住
      - 解决：`run_in_executor` 将计算扔到线程池，释放主线程
  
  - 音频文件保存到 `backend/data/audios/{file_hash}.mp3`
  - 验证文件大小（< 1GB）
  - 验证文件格式（MP3, WAV）
  - 获取音频时长（使用 `pydub` 或 `ffprobe`）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档自动生成（访问 `/docs`）
  - [ ] 可以通过 Postman 测试上传音频
  - [ ] 文件去重测试通过：相同文件只存储一次
  - [ ] **异步 MD5 测试通过**（Critical ⚠️）：
    - 上传 100MB 文件期间，其他 API 请求（如 `GET /episodes`）响应延迟 < 100ms
    - 并发上传 3 个文件，所有文件都能正常计算 MD5（无死锁）
  - [ ] MD5 计算性能测试：100MB 文件 < 5 秒
  - [ ] 转录进度轮询正常工作

---

### 阶段 2：前端播放器 + 字幕展示（Week 2）

#### Task 2.1：音频播放器组件
**优先级**: P0  
**预计工时**: 6 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/AudioPlayer.test.jsx`
  - 测试组件渲染
  - 测试播放/暂停切换
  - 测试进度条拖动（更新 `currentTime`）
  - 测试音量控制
  - 测试 Hover 状态（按钮背景色变化）
  - 测试 Active 状态（按钮按下效果）

- [ ] **实现组件**：创建 `frontend/src/components/AudioPlayer.jsx`
  - 使用 HTML5 `<audio>` + MUI `Box`/`IconButton` 组件
  - 状态管理：
    - `currentTime`：当前播放时间（秒）
    - `duration`：音频总时长（秒）
    - `isPlaying`：播放状态（布尔值）
    - `volume`：音量（0-1）
  - 实现控制功能：
    - 播放/暂停按钮（PlayArrow / Pause 图标）
    - 进度条（MUI `Slider` 组件）
    - 时间显示（`00:00 / 05:30` 格式）
    - 音量按钮（VolumeUp / VolumeMute 图标）

- [ ] **交互状态验证**（三状态原则）
  - Normal：默认蓝色按钮
  - Hover：背景色加深（`sx={{ '&:hover': { bgcolor: 'primary.dark' } }}`）
  - Active：点击时涟漪效果 + 轻微缩放（`sx={{ '&:active': { transform: 'scale(0.95)' } }}`）

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 可以播放测试音频
  - [ ] 拖动进度条实时更新播放位置
  - [ ] 按钮交互流畅（无延迟）

---

#### Task 2.2：实时滚动字幕组件
**优先级**: P0  
**预计工时**: 8 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/TranscriptView.test.jsx`
  - 测试组件渲染（模拟 API 数据）
  - 测试根据 `currentTime` 自动高亮当前字幕
  - 测试点击字幕跳转音频（调用 `onSeek` 回调）
  - 测试自动滚动（当前字幕始终在可视区域）

- [ ] **实现组件**：创建 `frontend/src/components/TranscriptView.jsx`
  - 使用 MUI `List` + `ListItem` 组件
  - Props:
    - `segments`：TranscriptSegment 数组
    - `currentTime`：当前播放时间
    - `onSeek(time)`：点击字幕的回调函数
  - 逻辑实现：
    - 根据 `currentTime` 找到当前激活的 segment（`start_time <= currentTime <= end_time`）
    - 高亮当前 segment（背景色 `bgcolor: 'action.selected'`）
    - 使用 `useRef` + `scrollIntoView` 实现自动滚动
  - 交互实现：
    - 点击任意 segment → 调用 `onSeek(segment.start_time)`

- [ ] **样式优化**
  - 当前字幕：蓝色背景 + 加粗字体
  - 普通字幕：灰色文本
  - Hover 状态：浅灰色背景
  - 间距：每个 segment 之间留 8px 间距

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 字幕随音频实时高亮
  - [ ] 点击字幕后音频跳转成功
  - [ ] 长字幕列表滚动流畅（无卡顿）

---

#### Task 2.3：前后端联调 - Episode 页面
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **创建页面**：`frontend/src/pages/EpisodePage.jsx`
  - 从 URL 参数获取 `episode_id`（使用 React Router）
  - 从 API 获取 Episode 详情（`GET /api/episodes/{id}`）
  - 渲染 AudioPlayer + TranscriptView
  - 实现音频与字幕同步：
    - AudioPlayer 的 `currentTime` → 传递给 TranscriptView
    - TranscriptView 的 `onSeek` → 更新 AudioPlayer 播放位置

- [ ] **状态管理**
  - 使用 `useState` 管理 `episode`, `segments`, `currentTime`
  - 使用 `useEffect` 拉取数据
  - 添加 Loading 状态（MUI `Skeleton` 组件）
  - 添加 Error 状态（MUI `Alert` 组件）

- [ ] **布局设计**
  - 顶部：Episode 标题 + 返回按钮
  - 中间：AudioPlayer（固定在顶部）
  - 底部：TranscriptView（占据剩余空间，可滚动）

- [ ] **验收标准**
  - [ ] 页面正常渲染
  - [ ] 音频播放时字幕同步高亮
  - [ ] 点击字幕后音频跳转
  - [ ] Loading 和 Error 状态正常显示

---

### 阶段 3：划线 + 笔记功能（Week 3）

#### Task 3.1：字幕划线功能（前端）
**优先级**: P0  
**预计工时**: 10 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/HighlightFeature.test.jsx`
  - 测试文本选择（模拟 `mouseup` 事件）
  - 测试划线保存（模拟 API 调用）
  - 测试划线渲染（验证背景色）
  - 测试删除划线

- [ ] **实现划线逻辑**：在 `TranscriptView.jsx` 中添加
  - 监听 `onMouseUp` 事件：
    ```javascript
    const handleMouseUp = () => {
      const selection = window.getSelection();
      if (selection.toString().length > 0) {
        setSelectedText(selection.toString());
        setMenuAnchor({ x: event.clientX, y: event.clientY });
      }
    };
    ```
  - 弹出操作菜单（MUI `Popover` 组件）：
    - 按钮 1：「AI 查询」
    - 按钮 2：「记录想法」
    - 按钮 3：「取消」
  - 点击「记录想法」：
    - 发送 `POST /api/highlights` 保存划线数据
    - 本地更新 UI（在文本上添加背景色）

- [ ] **划线渲染**：
  - 从 API 获取已有的 Highlight 数据（`GET /api/episodes/{id}/highlights`）
  - 在对应的 segment 文本中标记高亮（使用 `<mark>` 标签或 MUI `Box` 包裹）
  - 支持多个划线（不同颜色）

- [ ] **验收标准**
  - [ ] 选中文本后弹出菜单
  - [ ] 点击「记录想法」后文本高亮
  - [ ] 刷新页面后划线保持

---

#### Task 3.2：Highlight API（后端）
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **测试先行**：编写 `backend/tests/test_highlight_api.py`
  - 测试创建划线（验证 `start_offset` 和 `end_offset`）
  - 测试获取划线列表
  - 测试删除划线
  - 测试级联删除：删除 Highlight 时自动删除关联的 Note

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由（⭐ 简化）
  ```python
  # POST /api/highlights
  # 功能：创建划线（自动拆分 + 分组管理）⭐
  # 请求：{ 
  #   "episode_id": 1, 
  #   "highlights": [  # ⭐ 数组，前端已拆分
  #     {
  #       "cue_id": 10,
  #       "start_offset": 6,
  #       "end_offset": 12,
  #       "highlighted_text": "world.",
  #       "color": "#9C27B0"
  #     },
  #     {
  #       "cue_id": 11,
  #       "start_offset": 0,
  #       "end_offset": 15,
  #       "highlighted_text": "This is a test.",
  #       "color": "#9C27B0"
  #     }
  #   ],
  #   "highlight_group_id": "uuid-12345"  # ⭐ 可选，跨 cue 时提供
  # }
  # 响应：{ 
  #   "success": true,
  #   "highlight_ids": [1, 2],  # 创建的 Highlight ID 列表
  #   "highlight_group_id": "uuid-12345",  # 如果是分组
  #   "created_at": "..." 
  # }

  # GET /api/episodes/{id}/highlights
  # 功能：获取某个 Episode 的所有划线
  # 响应：[ 
  #   { 
  #     "id": 1, 
  #     "cue_id": 10,  # ⭐ 只有一个 cue_id
  #     "highlighted_text": "taxonomy", 
  #     "start_offset": 5, 
  #     "end_offset": 13,
  #     "color": "#9C27B0",
  #     "highlight_group_id": null,  # ⭐ 单 cue 划线
  #     "notes": [...]
  #   },
  #   { 
  #     "id": 2, 
  #     "cue_id": 10,
  #     "highlighted_text": "world.", 
  #     "start_offset": 6, 
  #     "end_offset": 12,
  #     "color": "#9C27B0",
  #     "highlight_group_id": "uuid-12345",  # ⭐ 分组 ID（跨 cue）
  #     "notes": [...]
  #   },
  #   { 
  #     "id": 3, 
  #     "cue_id": 11,
  #     "highlighted_text": "This is a test.", 
  #     "start_offset": 0, 
  #     "end_offset": 15,
  #     "color": "#9C27B0",
  #     "highlight_group_id": "uuid-12345",  # ⭐ 同一组
  #     "notes": [...]
  #   },
  #   ... 
  # ]

  # DELETE /api/highlights/{id}
  # 响应：{ 
  #   "success": true, 
  #   "deleted_highlights_count": 3,  # ⭐ 按组删除
  #   "deleted_notes_count": 2,
  #   "deleted_ai_queries_count": 1
  # }
  # 说明：
  # - 如果 Highlight 有 highlight_group_id，删除整组
  # - 级联删除关联的 Note 和 AIQueryRecord
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档更新
  - [ ] 级联删除测试通过：删除 Highlight 后，关联的 Note 被自动删除

---

#### Task 3.3：笔记双向链接（前端）
**优先级**: P0  
**预计工时**: 12 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/NotePanel.test.jsx`
  - 测试笔记渲染（与划线对齐）
  - 测试笔记滚动跟随
  - 测试点击笔记 → 字幕滚动
  - 测试创建笔记

- [ ] **实现布局**：创建 `frontend/src/components/NotePanel.jsx`
  - 使用 MUI `Grid` 或 `Stack` 实现左右分栏：
    - 左侧（60%）：TranscriptView（带划线）
    - 右侧（40%）：NoteList
  - 使用 `position: sticky` 固定分栏布局

- [ ] **实现「始终跟随划线源」逻辑**
  - 为每个 Highlight 计算其在左侧的垂直位置（`offsetTop`）
  - 在右侧对应位置渲染关联的 Note
  - 监听左侧滚动事件 → 同步右侧笔记位置（使用 `IntersectionObserver`）

- [ ] **实现双向链接**
  - 点击右侧笔记 → 左侧滚动到对应划线 + 高亮划线
  - 点击左侧划线 → 右侧滚动到对应笔记（如果存在）

- [ ] **验收标准**
  - [ ] 笔记与划线源在同一水平线
  - [ ] 滚动时笔记跟随划线移动
  - [ ] 双向点击导航正常工作

---

#### Task 3.4：Note API（后端）
**优先级**: P0  
**预计工时**: 4 小时

- [ ] **测试先行**：编写 `backend/tests/test_note_api.py`
  - 测试创建笔记
  - 测试更新笔记
  - 测试删除笔记
  - 测试获取笔记列表

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由
  ```python
  # POST /api/notes
  # 请求：{ "episode_id": 1, "highlight_id": 5, "content": "...", "note_type": "thought" }
  # 响应：{ "id": 1, "created_at": "..." }

  # PUT /api/notes/{id}
  # 请求：{ "content": "..." }
  # 响应：{ "success": true }

  # DELETE /api/notes/{id}
  # 响应：{ "success": true }

  # GET /api/episodes/{id}/notes
  # 响应：[ { "id": 1, "highlight_id": 5, "content": "...", ... }, ... ]
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] Swagger 文档更新

---

### 阶段 4：AI 查询功能（Week 4）

#### Task 4.1：AI 查询服务（后端）
**优先级**: P1（重要）  
**预计工时**: 8 小时

- [ ] **测试先行**：编写 `backend/tests/test_ai_service.py`
  - 测试单词翻译（`query_type: "word_translation"`）
  - 测试短语解释（带上下文）
  - 测试专有名词识别（如 "React", "OpenAI"）
  - 测试错误处理（API 超时、无效响应）

- [ ] **选择 AI API**
  - 方案 A（免费）：Google Translate API（单词翻译）
  - 方案 B（低成本）：OpenAI GPT-3.5-turbo（短语和专有名词）
  - 在 `backend/app/services/ai_service.py` 中实现

- [ ] **实现 AI 查询逻辑**
  ```python
  class AIService:
      def query(self, text: str, context: str, query_type: str) -> str:
          """
          text: 用户划线的文本
          context: 相邻 2-3 个 TranscriptSegment 的文本
          query_type: word_translation / phrase_explanation / concept
          """
          if query_type == "word_translation":
              return self.translate_word(text)
          elif query_type == "phrase_explanation":
              return self.explain_phrase(text, context)
          elif query_type == "concept":
              return self.explain_concept(text, context)
  ```

- [ ] **实现 API**：在 `backend/app/api.py` 添加路由
  ```python
  # POST /api/ai/query
  # 请求：{ "highlight_id": 5, "query_type": "word_translation" }
  # 响应：{ "response": "翻译结果...", "query_id": 1 }
  ```

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] 单词翻译成功率 > 95%
  - [ ] 短语解释包含上下文理解
  - [ ] API 响应时间 < 3 秒

---

#### Task 4.2：AI 查询界面（前端）
**优先级**: P1  
**预计工时**: 6 小时

- [ ] **测试先行**：编写 `frontend/src/components/__tests__/AIQueryDialog.test.jsx`
  - 测试弹窗打开/关闭
  - 测试 Loading 状态
  - 测试显示 AI 回复
  - 测试「添加到笔记」按钮

- [ ] **实现组件**：创建 `frontend/src/components/AIQueryDialog.jsx`
  - 使用 MUI `Dialog` 组件
  - 内容：
    - 顶部：用户划线的文本（加粗）
    - 中间：AI 回复（使用 `Typography` 组件）
    - 底部：「添加到笔记」按钮 + 「关闭」按钮
  - Loading 状态：显示 `CircularProgress`

- [ ] **集成到划线菜单**
  - 在 `TranscriptView.jsx` 的弹出菜单中添加「AI 查询」按钮
  - 点击后：
    - 发送 `POST /api/ai/query`
    - 打开 AIQueryDialog
    - 显示 Loading → 显示结果

- [ ] **实现「添加到笔记」功能**
  - 点击按钮 → 调用 `POST /api/notes`
  - 自动填充 AI 回复内容
  - 关闭弹窗 → 在右侧笔记列表显示新笔记

- [ ] **验收标准**
  - [ ] 所有测试用例通过
  - [ ] AI 查询流程流畅（无卡顿）
  - [ ] 添加到笔记后立即显示

---

### 阶段 5：完善与优化（Week 5+）

#### Task 5.1：错误处理与用户反馈
**优先级**: P1  
**预计工时**: 4 小时

- [ ] **后端统一异常处理**
  - 在 `backend/app/main.py` 添加全局异常处理器
  - 对所有 `HTTPException` 返回标准格式：
    ```json
    { "error": "错误信息", "code": "ERROR_CODE", "details": {} }
    ```

- [ ] **前端 Toast 通知**
  - 创建 `frontend/src/components/ToastProvider.jsx`（使用 MUI `Snackbar`）
  - 在所有 API 调用失败时显示 Toast
  - 成功操作也显示提示（如「笔记已保存」）

- [ ] **验收标准**
  - [ ] 所有错误都有友好提示
  - [ ] 无 Silent Failure

---

#### Task 5.2：性能优化
**优先级**: P2（中等）  
**预计工时**: 6 小时

- [ ] **后端优化**
  - 大文件转录采用分片处理（每 5 分钟一个分片）
  - 数据库添加索引：
    - `episodes.podcast_id`
    - `transcript_segments.episode_id`
    - `highlights.segment_id`
    - `notes.highlight_id`

- [ ] **前端优化**
  - 长字幕列表使用虚拟滚动（`react-window`）
  - 划线和笔记数据使用 `useMemo` 缓存
  - 图片懒加载（MUI `LazyLoad`）

- [ ] **验收标准**
  - [ ] 转录 30 分钟音频 < 10 分钟
  - [ ] 渲染 1000+ 字幕片段无卡顿
  - [ ] 内存占用 < 500MB

---

#### Task 5.3：文档更新
**优先级**: P2  
**预计工时**: 2 小时

- [ ] **每个任务完成后更新 `docs/changelog.md`**
  - 格式：`[2025-12-23] [feat] - 实现字幕划线功能 (TranscriptView.jsx, api.py)`

- [ ] **更新 README**
  - 添加项目介绍
  - 添加安装步骤
  - 添加使用说明

- [ ] **API 文档**
  - 访问 `http://localhost:8000/docs` 查看 Swagger 文档
  - 截图保存到 `docs/api_docs.png`

---

## 四、开发节奏

| 周次 | 阶段 | 核心目标 | 产出 |
|------|------|----------|------|
| **Week 1** | 后端数据层 + Whisper | 搭建后端核心功能 | - **8 个数据库表**创建成功<br>- **虚拟分段 + 临时文件转录**实现<br>- **文件去重**（MD5 hash）<br>- Episode 管理 API 完成<br>- 所有后端测试通过 |
| **Week 2** | 前端播放器 + 字幕展示 | 实现音频播放和字幕同步 | - AudioPlayer 组件完成<br>- TranscriptView 组件完成（含 speaker 显示）<br>- EpisodePage 页面完成<br>- 音频与字幕实时同步 |
| **Week 3** | 划线 + 笔记基础功能 | 实现核心交互 | - 字幕划线功能完成<br>- **三种笔记类型**（underline/thought/ai_query）<br>- 笔记创建/编辑/删除完成<br>- 双向链接完成<br>- 笔记与划线源对齐 |
| **Week 4** | AI 查询 + 优化 | 完善 AI 功能 | - AI 查询功能完成<br>- 错误处理完善<br>- 性能优化完成<br>- **MVP 版本发布** |
| **Week 5+** | iPad 适配 + 高级功能 | 跨平台支持 | - 响应式布局完成<br>- Touch 交互优化<br>- 笔记搜索功能<br>- 笔记导出功能 |

---

## 五、关键技术决策

### 5.1 虚拟分段 + 临时文件（存储优化）⭐
**决策**：不物理切割音频文件，只在数据库中记录时间范围，转录时用 FFmpeg 实时提取片段到临时文件  
**理由**：
- 节省 50% 存储空间（只保留一份完整音频）
- 灵活性强：可随时调整分段策略（如改为 5 分钟一段）
- Python `tempfile.NamedTemporaryFile` 自动清理临时文件

**实现**（修正版 ⚠️）：
```python
with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp:
    subprocess.run([
        "ffmpeg", "-y", "-i", audio_path, 
        "-ss", str(start_time), 
        "-t", str(duration),
        # ⚠️ 不使用 -c copy！MP3 只能在关键帧切割，时间戳不精确
        "-ar", "16000",      # Whisper 需要 16kHz
        "-ac", "1",          # 单声道
        "-c:a", "pcm_s16le", # PCM 编码，精准切割
        temp.name
    ], check=True)
    cues = whisper_service.transcribe(temp.name)
# 临时文件自动删除
```

**关键技术修正**（Critical ⚠️）：
- **禁止使用 `-c copy`**：
  - MP3 是压缩格式，只能在关键帧（Keyframe）处切割
  - 如果指定的 `start_time` 不是关键帧，FFmpeg 会寻找最近的关键帧
  - 导致切出的音频有几秒偏差，Whisper 识别的时间戳整体偏移
  - 后果：字幕和音频对不上（严重 Bug）

- **改用 WAV（PCM）格式**：
  - 秒级精准切割（无关键帧限制）
  - Whisper 内部也需要转为 16kHz Mono，提前转码节省加载时间
  - 性能影响：3 分钟片段转码 < 2 秒（完全可接受）

### 5.1.1 临时文件清理策略（避免磁盘占用过高）

**问题**：
- 转录失败时，临时文件会保留在 `backend/data/temp_segments/` 中
- 如果不清理，磁盘占用会持续增长
- 孤儿文件（对应的 Segment 已删除或长时间未重试）会永久占用空间

**清理策略**：
1. **成功转录后立即删除**：转录成功后，立即删除临时文件，清空 `segment_path`
2. **失败后保留 24 小时**：给用户足够的重试时间
3. **定期后台清理**：每天凌晨 3 点运行清理任务

**实现**：
```python
# backend/app/services/cleanup_service.py
import os
from datetime import datetime, timedelta
from app.database import get_db
from app.models import AudioSegment

def cleanup_orphan_temp_files():
    """清理孤儿临时文件（超过 24 小时的失败转录）"""
    db = next(get_db())
    cutoff_time = datetime.utcnow() - timedelta(hours=24)
    
    # 1. 查找所有超过 24 小时的 failed Segment
    old_failed_segments = db.query(AudioSegment).filter(
        AudioSegment.status == "failed",
        AudioSegment.created_at < cutoff_time,
        AudioSegment.segment_path != None
    ).all()
    
    for segment in old_failed_segments:
        # 2. 删除临时文件
        if os.path.exists(segment.segment_path):
            os.remove(segment.segment_path)
        
        # 3. 清空路径
        segment.segment_path = None
    
    db.commit()
    
    # 4. 清理孤儿文件（文件存在但数据库中无对应记录）
    temp_dir = "backend/data/temp_segments/"
    if os.path.exists(temp_dir):
        for filename in os.listdir(temp_dir):
            file_path = os.path.join(temp_dir, filename)
            file_age = datetime.utcnow() - datetime.fromtimestamp(os.path.getmtime(file_path))
            
            # 超过 24 小时的文件
            if file_age > timedelta(hours=24):
                # 检查数据库中是否存在对应的 Segment
                segment = db.query(AudioSegment).filter(
                    AudioSegment.segment_path == file_path
                ).first()
                
                # 如果不存在，说明是孤儿文件，删除
                if not segment:
                    os.remove(file_path)
```

**定时任务**（使用 APScheduler）：
```python
# backend/app/scheduler.py
from apscheduler.schedulers.background import BackgroundScheduler
from app.services.cleanup_service import cleanup_orphan_temp_files

scheduler = BackgroundScheduler()

# 每天凌晨 3 点运行清理任务
scheduler.add_job(
    cleanup_orphan_temp_files,
    'cron',
    hour=3,
    minute=0
)

scheduler.start()
```

**优势**：
- 自动清理过期临时文件，避免磁盘占用过高
- 给用户足够的重试时间（24 小时）
- 清理孤儿文件，防止数据泄漏

### 5.2 文件去重（MD5 hash + 异步计算）⚠️
**决策**：使用 MD5 hash 标识音频文件，避免重复存储  
**理由**：
- 相同文件只存储一次（节省空间）
- 用户重复上传时直接加载已有数据（提升体验）
- MD5 计算速度快（100MB 文件 < 5 秒）

**实现**（修正版 - 必须异步）：
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor()

def calculate_md5_sync(file_path: str) -> str:
    """同步版本的 MD5 计算（在线程池中执行）"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):  # 1MB chunks
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

@app.post("/upload")
async def upload_file(file: UploadFile):
    # 先保存到临时文件
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        shutil.copyfileobj(file.file, f)
    
    # 异步计算 MD5（不阻塞其他请求）
    loop = asyncio.get_event_loop()
    file_hash = await loop.run_in_executor(executor, calculate_md5_sync, temp_path)
    # ...
```

**关键技术修正**（Critical ⚠️）：
- **必须使用 ThreadPoolExecutor**：
  - 问题：即使分块读取，MD5 计算是 CPU 密集型任务，受 Python GIL 限制
  - 影响：上传 500MB 文件计算 MD5 需要 20-30 秒，期间主线程被阻塞
  - 后果：其他用户的 API 请求（如获取字幕）会被卡住，无响应
  - 解决：`run_in_executor` 将计算扔到线程池，释放主线程处理其他请求

### 5.3 异步转录
**决策**：使用 FastAPI `BackgroundTasks` 处理 Whisper 转录  
**理由**：避免阻塞 API，提升用户体验（前端可以轮询状态）

### 5.4 字幕数据结构（Cue）
**决策**：使用 `TranscriptCue` 表，包含 `speaker` 字段，对应 PRD 的 cue 结构  
**理由**：
- 与 PRD 术语保持一致（cue，不是 segment）
- 支持说话人标识（PRD 必需）
- Whisper 使用 `word_timestamps=True` 提供精准时间戳

### 5.4.1 Episode 表优化（消除数据冗余）⭐ 新增
**决策**：删除 `Episode.show_name` 字段，使用 `@property` 动态获取（方案 1）  
**理由**：
- **消除数据冗余**：`show_name` 与 `Podcast.title` 本质相同，违反 3NF 范式
- **保证数据一致性**：修改 Podcast.title 时无需同步更新所有 Episode
- **简化数据维护**：无需编写同步逻辑
- **性能影响可控**：SQLAlchemy `joinedload` 可避免 N+1 查询，数据量不大时 JOIN 性能可忽略

**实现**：
```python
class Episode(Base):
    podcast = relationship("Podcast", back_populates="episodes")
    
    @property
    def show_name(self):
        """动态获取节目名称"""
        return self.podcast.title if self.podcast else "本地音频"
```

**查询优化**：
```python
# 使用 joinedload 避免 N+1 查询
episodes = db.query(Episode).options(joinedload(Episode.podcast)).all()
for episode in episodes:
    print(episode.show_name)  # 高效访问，无额外查询
```

### 5.4.2 分段信息全局配置（便于实验调优）⭐ 新增
**决策**：删除 Episode 表的分段相关字段（needs_segmentation、segment_duration、total_segments），改为全局配置 + @property  
**理由**：
- **大多数音频都需要分段**：单独存储 `needs_segmentation` 意义不大
- **分段阈值是系统级参数**：不是每个 Episode 独立配置，应集中管理
- **需要频繁调整以找最优值**：平衡转录速度和用户体验
- **便于实验**：修改 `config.py` 后，所有 Episode 自动生效，无需更新数据库
- **消除数据冗余**：派生属性不应存储，符合单一数据源原则

**实现**：
```python
# backend/app/config.py
SEGMENT_DURATION = 180  # 全局配置，可调整

# backend/app/models.py
class Episode(Base):
    duration = Column(Float, nullable=False)  # 只存储固有属性
    
    @property
    def segment_duration(self):
        from app.config import SEGMENT_DURATION
        return SEGMENT_DURATION
    
    @property
    def needs_segmentation(self):
        return self.duration > self.segment_duration
    
    @property
    def total_segments(self):
        if not self.needs_segmentation:
            return 1
        import math
        return math.ceil(self.duration / self.segment_duration)
```

**实验流程**：
```python
# 实验 1：测试 120 秒分段
SEGMENT_DURATION = 120  # 修改配置，重启服务
# 所有 Episode 自动使用新值

# 实验 2：测试 300 秒分段
SEGMENT_DURATION = 300  # 修改配置，重启服务
# 无需更新数据库，立即生效
```

### 5.4.3 字幕排序最终方案（Critical ⭐⭐⭐）⭐ 最终确定
**决策**：保留 `cue_index` 字段并实现重新索引机制，Highlight 使用 `cue.id` 关联  
**理由**：
- **用户体验优先**：字幕和笔记必须按顺序展示，`cue_index` 提供明确的显示顺序
- **异步转录支持**：通过重新索引机制，保证 `cue_index` 全局连续（1, 2, 3...）
- **关联稳定性**：Highlight 使用 `cue.id`（主键）关联，不受 `cue_index` 变化影响
- **查询性能**：`ORDER BY cue_index` 比 `ORDER BY start_time` 更高效（整数索引）
- **符合 PRD**：用户无感知后端实现细节，只看到正确的顺序

**实现**：
```python
# TranscriptCue：保留 cue_index（全局连续）
class TranscriptCue(Base):
    cue_index = Column(Integer, nullable=False, index=True)  # ⭐ 全局连续索引
    start_time = Column(Float, nullable=False, index=True)   # 用于重新索引排序
    
# 保存字幕并重新索引
def save_cues_to_db(cues: List[Dict], segment: AudioSegment, db: Session):
    """保存字幕并重新索引（保证 cue_index 全局连续）"""
    # Step 1: 创建新 cue（临时 cue_index=0）
    new_cues = [
        TranscriptCue(
            episode_id=segment.episode_id,
            segment_id=segment.id,
            start_time=cue["start"] + segment.start_time,
            end_time=cue["end"] + segment.start_time,
            speaker=cue.get("speaker", "Unknown"),
            text=cue["text"],
            cue_index=0  # 临时值
        )
        for cue in cues
    ]
    
    # Step 2: 保存新 cue（获取 ID）
    db.add_all(new_cues)
    db.flush()
    
    # Step 3: 重新索引 - 查询该 Episode 的所有 cue，按 start_time 排序
    all_cues = db.query(TranscriptCue).filter(
        TranscriptCue.episode_id == segment.episode_id
    ).order_by(TranscriptCue.start_time).all()
    
    # Step 4: 统一分配连续的 cue_index
    for index, cue in enumerate(all_cues, start=1):
        cue.cue_index = index  # 1, 2, 3, 4...
    
    db.commit()

# 查询逻辑（两种方式）
def get_cues(episode_id):
    # 方式 1：按 cue_index 排序（推荐，性能更好）
    return db.query(TranscriptCue).filter(
        TranscriptCue.episode_id == episode_id
    ).order_by(TranscriptCue.cue_index).all()
    
    # 方式 2：按 start_time 排序（语义更清晰）
    # return db.query(TranscriptCue).filter(
    #     TranscriptCue.episode_id == episode_id
    # ).order_by(TranscriptCue.start_time).all()

# 前端显示（直接使用 cue_index）
cues.map((cue) => ({
    ...cue,
    displayIndex: cue.cue_index  // 1, 2, 3, 4...
}))

# Highlight 关联（Critical ⭐⭐⭐）
class Highlight(Base):
    cue_id = Column(Integer, ForeignKey("transcript_cues.id"))  # ⭐ 使用主键
    # 不使用 cue_index，避免重新分配问题
```

**关键场景**（详细说明）：
1. **顺序转录**：
   - segment_001 完成 → 生成 cue（id=1,2,3），cue_index = 1, 2, 3
   - segment_002 完成 → 生成 cue（id=4,5），重新索引后 cue_index = 1, 2, 3, 4, 5

2. **乱序转录**（异步场景）：
   - segment_002 先完成 → 生成 cue（id=10,11），cue_index = 1, 2
   - 用户在 id=10 的 cue 上创建 Highlight（cue_id=10）
   - segment_001 后完成 → 生成 cue（id=20,21,22），重新索引后：
     - cue id=20,21,22 的 cue_index = 1, 2, 3（segment_001）
     - cue id=10,11 的 cue_index = 4, 5（segment_002）
   - Highlight 仍然关联 cue_id=10（关联不受影响）

3. **转录失败与重试**：
   - segment_001 失败 → 不生成 cue
   - segment_002 完成 → 生成 cue（id=10,11），cue_index = 1, 2
   - segment_001 重试成功 → 生成 cue（id=20,21,22），重新索引后：
     - cue id=20,21,22 的 cue_index = 1, 2, 3（segment_001）
     - cue id=10,11 的 cue_index = 4, 5（segment_002）

4. **Highlight 稳定性**（关键保证）：
   - 使用 `cue.id` 关联，永不改变
   - cue_index 变化不影响 Highlight 关联
   - 笔记始终显示在正确的字幕位置

**并发安全**（Critical ⚠️）：
```python
# 使用数据库事务保证原子性
with db.begin():
    # 保存 cue + 重新索引
    save_cues_to_db(cues, segment, db)
    
# 建议：在 Episode 级别加锁（悲观锁）
from sqlalchemy import select
episode = db.query(Episode).with_for_update().get(episode_id)  # 行锁
```

**索引优化**：
```sql
-- cue_index 索引（主要查询索引，性能最优）
CREATE INDEX idx_episode_cue_index ON transcript_cues(episode_id, cue_index);
-- start_time 索引（用于重新索引排序）
CREATE INDEX idx_episode_time ON transcript_cues(episode_id, start_time);
```

**优点总结**：
- ✅ `cue_index` 全局连续，前端无需动态计算
- ✅ 查询性能好（整数索引）
- ✅ Highlight 关联稳定（使用主键）
- ✅ 用户体验完美（无感知异步转录）
- ✅ 符合 PRD（字幕和笔记按顺序展示）

**缺点与解决**：
- ⚠️ 重新索引有性能开销 → 解决：每个 Episode 的 cue 数量有限（< 1000），重新索引 < 100ms
- ⚠️ 并发安全问题 → 解决：使用数据库事务 + 行锁
- ⚠️ 实现复杂度增加 → 解决：封装到 `save_cues_to_db` 函数，调用简单

### 5.4.4 用户体验设计原则："无感知"异步转录 ⭐⭐⭐ 新增
**决策**：用户完全无感知音频被切分和异步转录的实现细节  
**理由**：
- **PRD 核心需求**：用户上传音频 → 看到字幕依次展示 → 划线 → 生成笔记 → 下次打开笔记按顺序展示
- **用户不关心**：音频被切成几段、哪段先转录完成、转录失败重试
- **用户只关心**：字幕和笔记是否按正确顺序展示

**实现策略**：
1. **字幕顺序保证**：
   - 后端：使用 `cue_index` 全局连续索引，基于 `start_time` 排序
   - 前端：按 `cue_index` 或 `start_time` 排序展示
   - 结果：用户看到的字幕始终按时间顺序，无乱序

2. **笔记顺序保证**：
   - Highlight 使用 `cue.id`（主键）关联，不受 `cue_index` 变化影响
   - 笔记通过 `Highlight → TranscriptCue` 关联链，按 `cue_index` 排序
   - 结果：用户下次打开时，笔记仍然按正确顺序展示

3. **转录进度展示**（用户层）：
   - 隐藏分段信息："被切成 4 段"（技术细节）
   - 展示百分比："已完成 67%"（用户关心）
   - 展示剩余时间："预计还需 2 分钟"（用户关心）

4. **转录失败处理**（用户层）：
   - 隐藏具体错误："segment_002 转录失败: FFmpeg error"（技术细节）
   - 展示友好提示："部分字幕转录失败，请重试"（用户理解）
   - 提供重试按钮：一键重试失败的部分

**用户体验验收标准**：
- [ ] 用户上传音频后，看到字幕依次加载（从上到下）
- [ ] 用户在任意字幕上划线，笔记显示在正确位置
- [ ] 用户关闭页面后再打开，笔记仍然按顺序展示
- [ ] 用户无法感知音频被切分或异步转录
- [ ] 转录进度显示直观（百分比 + 剩余时间），无技术术语

**开发者调试层**（仅供后台/日志）：
- 显示分段信息："总段数 4，已完成 2，失败 1，待处理 1"
- 显示详细错误："segment_002 转录失败: FFmpeg error: Invalid codec"
- 提供调试工具：查看每段的转录状态、重试次数

### 5.4.5 Highlight 简化设计（单 cue + 分组管理）⭐⭐⭐ 新增
**决策**：不允许单个 Highlight 跨 cue，改为自动拆分 + 分组管理  
**理由**：
- **核心问题**：如果允许 Highlight 跨 cue（start_cue_id + end_cue_id），异步转录时 cue 顺序变化会导致 Highlight 错乱
- **简化方案**：
  - 每个 Highlight 只关联一个 cue（cue_id）
  - 如果用户跨 cue 划线，前端自动拆分成多个 Highlight
  - 使用 `highlight_group_id`（UUID）关联同一次划线
  - 删除时按组删除，用户无感知
- **用户体验**：
  - 用户可以跨 cue 划线（自动拆分，用户看不到）
  - 笔记和划线按顺序展示
  - 完全符合 PRD 要求

**实现**：
```python
# Highlight 模型（简化！）
class Highlight(Base):
    cue_id = Column(Integer, ForeignKey("transcript_cues.id"))  # ⭐ 单 cue 关联
    start_offset = Column(Integer)
    end_offset = Column(Integer)
    highlighted_text = Column(Text)
    highlight_group_id = Column(String, nullable=True, index=True)  # ⭐ 分组 ID
    color = Column(String, default="#9C27B0")

# 前端划线逻辑
function handleTextSelection(selection) {
    const affectedCues = getAffectedCues(selection);
    
    if (affectedCues.length === 1) {
        // 单 cue 划线（90% 场景）
        createHighlight({
            cue_id: affectedCues[0].id,
            start_offset: selection.startOffset,
            end_offset: selection.endOffset,
            highlight_group_id: null
        });
    } else {
        // 跨 cue 划线（10% 场景）
        const groupId = generateUUID();
        affectedCues.forEach((cue, index) => {
            createHighlight({
                cue_id: cue.id,
                start_offset: index === 0 ? selection.startOffset : 0,
                end_offset: index === affectedCues.length - 1 ? selection.endOffset : cue.text.length,
                highlight_group_id: groupId  // ⭐ 同一组
            });
        });
    }
}

# 删除逻辑
def delete_highlight(highlight_id):
    highlight = db.query(Highlight).get(highlight_id)
    if highlight.highlight_group_id:
        # 按组删除
        db.query(Highlight).filter(
            Highlight.highlight_group_id == highlight.highlight_group_id
        ).delete()
    else:
        db.delete(highlight)
    db.commit()
```

**优点**：
- ✅ 极大简化设计：每个 Highlight 只关联一个 cue
- ✅ 完全解决 cue_index 变化问题：使用 `cue.id`（主键），永不变化
- ✅ 前端渲染简单：每个 cue 独立渲染高亮
- ✅ 符合 90% 的实际使用场景（单词/句子划线）
- ✅ 通过分组管理仍然支持跨 cue 划线（用户无感知）

### 5.4.5 转录状态双层设计（用户体验优化）⭐ 新增
**决策**：删除 Episode 表的转录状态字段，使用 `@property` 分层设计（用户层 + 调试层）  
**理由**：
- **用户体验优先**：隐藏技术细节（分段），只显示结果（进度、剩余时间）
- **关注点分离**：用户看简洁信息，开发者看详细数据
- **保证数据一致性**：Segment 状态为单一数据源
- **符合产品原则**："Don't Make Me Think" - 用户不需要知道"被切成几段"

**用户界面层**（隐藏技术细节）：
```python
episode.transcription_progress          # → 67.0（百分比）
episode.transcription_status_display    # → "正在转录中..."
episode.estimated_time_remaining        # → 90（秒）
```

**开发调试层**（完整技术数据）：
```python
episode.transcription_stats             # → {"total_segments": 4, "completed": 2, ...}
episode.failed_segments_detail          # → [{"segment_id": "002", "error": "..."}]
```

**前端展示示例**：
```javascript
// ✅ 用户看到
<LinearProgress value={episode.transcription_progress} />
<Typography>{episode.transcription_status_display}</Typography>
<Typography>预计还需 {formatTime(episode.estimated_time_remaining)}</Typography>

// 🔧 开发者调试页面看到
<DebugPanel stats={episode.transcription_stats} />
```

### 5.5 笔记类型（三种）
**决策**：`note_type` = `underline`/`thought`/`ai_query`  
**理由**：
- `underline`：纯划线（只有下划线样式，不显示笔记卡片）
- `thought`：用户想法（显示笔记卡片）
- `ai_query`：AI 查询结果（显示笔记卡片）
- 所有笔记都必须关联 `highlight_id`（划线操作）

### 5.6 划线数据结构
**决策**：保存 `start_offset` 和 `end_offset`（相对于 cue 的字符位置）  
**理由**：支持跨段落划线（未来扩展），避免存储重复文本

### 5.7 前端状态管理
**决策**：初期使用 React `useState` + Context，后期考虑 Zustand  
**理由**：快速开发，避免过度设计

### 5.8 AI API 选型
**决策**：
- 单词翻译：Google Translate API（免费）
- 短语解释：OpenAI GPT-3.5-turbo（低成本，约 $0.002/次）
- 专有名词：GPT-3.5-turbo + 上下文注入

**理由**：平衡成本和效果，避免高昂的 GPT-4 费用

### 5.9 数据库选型
**决策**：SQLite（本地文件数据库）  
**理由**：符合「Local-First」理念，无需额外部署数据库服务

### 5.10 测试策略
**决策**：TDD（测试驱动开发）  
**理由**：提前发现 Bug，保证代码质量，便于重构

---

## 附录：Definition of Done（完成标准）

每个任务完成后，必须满足以下标准：

- [ ] **测试通过**：所有单元测试和集成测试为绿色
- [ ] **UI 状态完整**：交互元素有 Normal、Hover、Active 三种状态
- [ ] **错误处理**：无 Silent Failure，用户看到友好提示
- [ ] **代码清理**：无 `console.log`、`print`、注释掉的代码
- [ ] **无硬编码**：魔法数字和 URL 提取到 `constants.py` 或 `config.js`
- [ ] **文档更新**：`docs/changelog.md` 已更新

---

## 结语

本开发计划遵循 **TDD + 迭代式开发 + 用户价值优先** 的原则，确保每个阶段都能产出可用的功能模块。

**下一步行动**：
1. 切换到 Agent 模式
2. 开始执行 **Task 1.1：数据库模型重构**
3. 祝开发顺利！🚀

